<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hello</title>
  
  <subtitle>严律己，宽待人</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.liwenguang.cn/"/>
  <updated>2018-06-10T17:30:00.000Z</updated>
  <id>http://www.liwenguang.cn/</id>
  
  <author>
    <name>TheOhters</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>十四、流量控制</title>
    <link href="http://www.liwenguang.cn/2018/06/11/distributed_principle_prictice/15.html/"/>
    <id>http://www.liwenguang.cn/2018/06/11/distributed_principle_prictice/15.html/</id>
    <published>2018-06-10T17:30:00.000Z</published>
    <updated>2018-06-10T17:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-屏蔽降级"><a href="#1-屏蔽降级" class="headerlink" title="1 屏蔽降级"></a>1 屏蔽降级</h1><h1 id="2-容错降级"><a href="#2-容错降级" class="headerlink" title="2 容错降级"></a>2 容错降级</h1><h1 id="3-业务层降级"><a href="#3-业务层降级" class="headerlink" title="3 业务层降级"></a>3 业务层降级</h1><h1 id="4-个人总结"><a href="#4-个人总结" class="headerlink" title="4 个人总结"></a>4 个人总结</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-屏蔽降级&quot;&gt;&lt;a href=&quot;#1-屏蔽降级&quot; class=&quot;headerlink&quot; title=&quot;1 屏蔽降级&quot;&gt;&lt;/a&gt;1 屏蔽降级&lt;/h1&gt;&lt;h1 id=&quot;2-容错降级&quot;&gt;&lt;a href=&quot;#2-容错降级&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>十四、流量控制</title>
    <link href="http://www.liwenguang.cn/2018/06/07/distributed_principle_prictice/14.html/"/>
    <id>http://www.liwenguang.cn/2018/06/07/distributed_principle_prictice/14.html/</id>
    <published>2018-06-07T14:30:00.000Z</published>
    <updated>2018-06-10T17:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>当资源成为瓶颈时，服务框架需要对消费者做限流，启动流控保护机制。</p><h1 id="1-静态流控"><a href="#1-静态流控" class="headerlink" title="1 静态流控"></a>1 静态流控</h1><p>主要针对客户端访问速率进行控制，它通常根据服务质量等级协定（SLA）中约定的 QPS做全局流量控制，例如订单服务的静态流控阈值为 100QPS，则无论集群有多少个订单服务实例，它们总的处理速率之和不能超过 100QPS。</p><h2 id="1-1-传统静态流控设计方案"><a href="#1-1-传统静态流控设计方案" class="headerlink" title="1.1 传统静态流控设计方案"></a>1.1 传统静态流控设计方案</h2><p>在软件安装时，根据集群服务节点个数和静态流控阈值，计算每个服务及诶单分摊的 QPS阈值，系统运行时，各个服务节点按照自己分配的阈值进行流控，对于超出流控阈值的请求则拒绝访问。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/14_1.png" alt=""><br>服务框架启动时，将本节点的静态流控阈值加载到内存中，服务框架通过 Handler拦截器咋服务调用前做拦截计数，当计数器在指定周期 T到达 QPS上限时，启动流控，拒绝信的请求消息接入。注意：  </p><ol><li>服务实例通常由多线程执行，因此计数时需要考虑线程并发安全，可以使用 Atomic原子类进行原子操作。</li><li>达到流控阈值之后拒绝新的请求消息接入，不能拒绝后续的应答消息，否则这会导致客户端超时或者触发 FailOver，增加服务端的负载。</li></ol><h2 id="1-2-传统方案的缺点"><a href="#1-2-传统方案的缺点" class="headerlink" title="1.2 传统方案的缺点"></a>1.2 传统方案的缺点</h2><ol><li>云端服务的弹性伸缩性使服务节点数处于动态变化过程中，预分配方案行不通。</li><li>服务节点宕机，或者有新的服务节点动态加入，导致服务节点数发生变化，静态分配的 QPS需要实时动态调整，否则会导致流控不准。</li></ol><p>当应用和服务迁移到云上之后， PaaS 平台的一个重要功能就是支持应用和服务的弹性伸缩，在云上，资源都是动态分配和调整的，静态分配阈值方案无法适应服务迁移到云上。</p><h2 id="1-3-动态配额分配制"><a href="#1-3-动态配额分配制" class="headerlink" title="1.3 动态配额分配制"></a>1.3 动态配额分配制</h2><p>原理：由服务注册中心以流控周期 T为单位，动态推送每个节点分配的流控阈值 QPS。当服务节点发生变更时，会触发服务注册中心重新计算每个节点的配额，然后进行推送，这样无论是新增还是减少服务节点数，都能够在下一个流控周期内被识别和处理。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/14_2.png" alt=""><br>而在生产环境中，每台机器/VM 的配置可能不同，如果每个服务节点采用流控总阈值/服务节点数这种平均主义，可能会发生性能高、处理快的节点配额很快用完，但是性能差的节点配额有剩余的情况，这会导致总的配额没用完，但是系统却发生了静态流控的问题。<br>解决方案一：根据各个服务节点的性能 KPI数据（例如服务调用平均时延）做加权。<br>解决方案二：配额指标返还和重新申请，每个服务节点根据自身分配的指标值、处理速率做预测，如果计算结果表明指标会有剩余，则把多余的返还给服务注册中心；对于配额已经使用完的服务节点，重新主动去服务注册中心申请配额，如果连续 N次都申请不到新的配额指标，则对于新接入的请求消息做流控。  </p><p>结合负载均衡进行静态流控，才能够实现更精确的调度和控制。消费者根据各服务节点的负载情况做加权路由，性能差的节点路由到的消息更少，这样保证了系统的负载均衡和配额的合理分配。</p><h2 id="1-4-动态配额申请制"><a href="#1-4-动态配额申请制" class="headerlink" title="1.4 动态配额申请制"></a>1.4 动态配额申请制</h2><p>尽管动态配额分配制可以解决节点变化引起的流控不准问题，也能改善平均主义配额分配缺点如下：</p><ol><li>如果流控周期 T比较大，各服务节点的负载情况变化比较快，服务节点的负载反馈到注册中心，统一计算后再做配额均衡，误差会比较大。</li><li>如果流控周期 T比较小，服务注册中心需要实时获取各服务节点的性能 KPI数据并计算负载情况，经过性能数据采集、上报、汇总和计算之后会有一定的时延，这会导致流控滞后产生误差。</li><li>如果采用配额返还和重新申请方式，则会增加交互次数，同时也会存在时序误差。</li><li>扩展性差，负载的汇总、计算和配额分配、下发都由服务注册中心完成，如果服务注册中心管理的节点数非常多，则服务注册中心的计算压力就非常大，随着服务节点数的增加服务注册中心配额分配效率会急速下降、系统不具备平滑扩展能力。  </li></ol><p>而动态配额申请制，工作原理如下：  </p><ol><li>系统部署的时候，根据服务节点数和静态流控 QPS阈值，拿出一定比例的配额做初始分配，剩余的配额放在配额资源池中。</li><li>哪个服务节点使用完了配额，就主动向服务注册中心申请配额。配额的申请策略是，如果流控周期为 T，则将周期 T分成更小的周期 T/N（N为经验值，默认值为 10），当前的服务节点数为 M个，则申请的配额为（总 QPS配额-已经分配的 QPS）/ M * T / N。</li><li>总的配额如果被申请完，则返回 0 配额给各个申请配额的服务节点，服务节点对新接入的请求消息进行流控。</li></ol><p>动态配额申请制的优点：</p><ol><li>各个服务节点最清楚自己的负载情况，性能 KPI数据在本地内存中计算获得，实时性高。</li><li>由各个服务节点根据自身负载情况去申请配额，保证性能高的节点有更高的配额，性能差的自然配额就少，实现合理资源，流控的精确性。</li></ol><h1 id="2-动态流控"><a href="#2-动态流控" class="headerlink" title="2 动态流控"></a>2 动态流控</h1><p>动态流控的最终目标是为了保命，并不是对流量或者访问速度做精确控制。<br>触发动态流控的因子是资源，资源又分为系统资源和应用资源两大类，根据不同的资源负载情况，动态流控又分为多个级别，每个级别流控系数都不同，也就是被拒绝掉的消息比例不同。每个级别都有相应的流控阈值，这个阈值通常支持在线动态调整。</p><h2 id="2-1-动态流控因子"><a href="#2-1-动态流控因子" class="headerlink" title="2.1 动态流控因子"></a>2.1 动态流控因子</h2><p>动态流控因子包括系统资源和应用资源两大类，常见的系统资源包括：</p><ol><li>应用进程所在主机/VM 的 CPU使用率。</li><li>应用进程所在主机/VM 的 内存使用率。  </li></ol><p>使用 java.lang.Process 执行 top、sar 等外部命令获取系统资源使用情况。<br>常用的应用资源：  </p><ol><li>JVM 堆内存使用率</li><li>消息队列积压率</li><li>会话积压率  </li></ol><p>具体实现策略是系统启动时拉起一个管理线程，定时采集应用资源的使用率，并刷新动态流控的应用资源阈值。</p><h2 id="2-2-分级流控"><a href="#2-2-分级流控" class="headerlink" title="2.2 分级流控"></a>2.2 分级流控</h2><p>不同级别拒掉的消息比例不同，例如一级流控拒绝掉 1/8 的消息；发生二级流控时，拒绝掉 1/4 消息。<br>为了防止系统波动导致的偶发性流控，无论是进入流控状态还是从流控状态恢复，都需要连续采集 N次并计算平均值，如果连续 N次平均值大于流控阈值，则进入流控状态。<br>而在一个流控周期内，不会发生流控级别的跳变。</p><h1 id="3-并发控制"><a href="#3-并发控制" class="headerlink" title="3 并发控制"></a>3 并发控制</h1><p>并发控制针对线程的并发执行数进行控制，它的本质是限制对某个服务或者服务的方法过度消息，耗用过多的资源而影响其它的服务的正常运行。有两种形式：  </p><ol><li>针对服务提供者的全局控制。</li><li>针对服务消费者的局部控制。</li></ol><h1 id="4-连接控制"><a href="#4-连接控制" class="headerlink" title="4 连接控制"></a>4 连接控制</h1><p>通常分布式服务框架服务提供者和消费者之间采用长连接私有协议，为了防止因为消费者连接数过多导致服务端负载压力过大，系统需要针对连接数进行流控。  </p><h1 id="5-并发和连接控制算法"><a href="#5-并发和连接控制算法" class="headerlink" title="5 并发和连接控制算法"></a>5 并发和连接控制算法</h1><p>并发连接的控制算法原理如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/14_3.png" alt=""></p><p>基于服务调用 Pipeline 机制，可以对请求消息接收和发送、应答消息接收和发送、异常消息等做切面拦截（类似 Spring 的 AOP 机制，但是没采用反射机制，性能更高），利用 Pipeline 拦截切面接口，对请求消息做服务调用前的拦截和计数，根据计数器做流控，服务端的算法如下：  </p><ol><li>获取流控阈值。</li><li>从全局 RPC上下文中获取当前的并发执行数，与流控阈值对比，如果小于流控阈值，则对当前的计数器做原子自增。</li><li>如果等于或者大于流控阈值，则抛出 RPC流控异常给客户端。</li><li>服务调用执行完成之后，获取 RPC上下文中的并发执行数，做原子自减。  </li></ol><p>客户端的算法如下：  </p><ol><li>获取流控阈值。</li><li>从全局 RPC上下文中获取当前的并发执行数，与流控阈值对比，如果小于流控阈值，则对当前的计数器做原子自增。</li><li>如果等于或大于流控阈值，则当前线程进入 wait状态， wait超时时间为服务调用的超时时间。</li><li>如果有其它线程服务调用完成，调用计数器自减，则并发执行数小于阈值，线程被 notify，退出 wait，继续执行。</li></ol><h1 id="6-个人总结"><a href="#6-个人总结" class="headerlink" title="6 个人总结"></a>6 个人总结</h1><p>流量控制是保证服务 SLA（Sevice-Level Agreement）的重要措施，也是业务高峰期故障预防和恢复的有效手段，分布式服务框架需要支持流控阈值、策略的在线调整，不需要重启应用即可生效。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当资源成为瓶颈时，服务框架需要对消费者做限流，启动流控保护机制。&lt;/p&gt;
&lt;h1 id=&quot;1-静态流控&quot;&gt;&lt;a href=&quot;#1-静态流控&quot; class=&quot;headerlink&quot; title=&quot;1 静态流控&quot;&gt;&lt;/a&gt;1 静态流控&lt;/h1&gt;&lt;p&gt;主要针对客户端访问速率进行控
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>十三、服务多版本</title>
    <link href="http://www.liwenguang.cn/2018/06/06/distributed_principle_prictice/13.html/"/>
    <id>http://www.liwenguang.cn/2018/06/06/distributed_principle_prictice/13.html/</id>
    <published>2018-06-06T13:24:00.000Z</published>
    <updated>2018-06-07T14:30:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>服务上线之后，由于功能变更、BUG修复，以及服务升级，需要对服务采用多版本管理。</p><h1 id="1-服务多版本管理设计"><a href="#1-服务多版本管理设计" class="headerlink" title="1 服务多版本管理设计"></a>1 服务多版本管理设计</h1><p>管理的对象包括服务提供者和消费者：  </p><ol><li>服务提供者：发布服务的时候，支持指定服务的版本号。</li><li>服务消费者：消费服务的时候，支持指定引用的服务版本号或者版本范围。</li></ol><h2 id="1-1-服务版本号管理"><a href="#1-1-服务版本号管理" class="headerlink" title="1.1 服务版本号管理"></a>1.1 服务版本号管理</h2><p>服务的版本号是有序的，在服务名相同的情况下，两个相同服务名的不同服务版本的版本号可以比较大小。完整的版本号由“主版本号（Major）+副版本号（Minor）+微版本号（Micro）”构成：  </p><ol><li>主版本号：表示重大特性或者功能变更，接口或功能可能会不兼容。</li><li>副版本号：发生了少部分功能变更，或者新增了一些功能。</li><li>微版本号：主要用于 BUG修改，对应于常见的 SP补丁包。</li></ol><h2 id="1-2-服务提供者"><a href="#1-2-服务提供者" class="headerlink" title="1.2 服务提供者"></a>1.2 服务提供者</h2><p>服务开发完成之后，需要将一个或者多个服务打包成一个 jar/war 包，为了便于对服务进行物理管理，打包后的名称中会包含服务的版本号信息，例如 com.huawei.orderService_1.0.1.jar。<br>在微服务架构中，微服务独立开发、打包、部署和升级，因此微服务的版本和软件包的版本可以一一映射。但是在实际开发中，尤其是大规模企业应用开发，单独为每个服务打包和部署目前尚未成为主流，它会增加服务软件包的管理和线上治理成本，因此目前的主流模式仍然是多个服务提供者合一个大的 jar/war 包，这就会存在一个问题：项目开发后期，有些服务进行了版本升级，有些服务没有，这样当它们被打包成同一个软件包时，就会导致版本号不一致。  </p><p>每个服务都指定一个版本号，对开发而言也比较麻烦。一个比较好的实践就是微服务+全局版本模式。对于经常发生功能变更、需要独立升级的服务，将其独立拆分出来进行微服务化，实现单个微服务级的打包和部署。  </p><p>对于其它服务，服务框架提供全局版本功能，在 Maven组件工程开发时，只需要为整个工程配置一个版本号，该组件工程包含的所有服务都共用该版本号。如果组件工程包含的某个服务发生了版本变更，就统一升级全局版本号，其它未发生功能变更但是打包在一起的服务做级联升级。这样做的一个原因是服务被打包在一起后，无论其它服务是否需要升级，只要软件包中的一个服务发生了版本升级，其它合设的服务也必须与其一起打包升级，它们之间存在物理上的耦合，这也是为什么微服务架构提倡微服务独立打包、部署和升级的原因。</p><h2 id="1-3-服务消费者"><a href="#1-3-服务消费者" class="headerlink" title="1.3 服务消费者"></a>1.3 服务消费者</h2><p>与服务提供者不同，服务消费者往往不需要指定具体依赖的服务版本，而是一版本范围，例如：version=“[1.0.1, 2.0.8]”。  </p><ol><li>消费者关心的是某个新特性从哪个服务版本中开始提供，它并不关系服务提供者的版本演进以及具体的版本号。</li><li>消费者想使用当前环境中服务的最新版本，但不清楚具体的版本号，希望自动适配最新的服务版本。</li></ol><p>当然需要指定一个默认的服务提供者版本号。</p><h2 id="1-4-基于版本号的服务路由"><a href="#1-4-基于版本号的服务路由" class="headerlink" title="1.4 基于版本号的服务路由"></a>1.4 基于版本号的服务路由</h2><p>服务提供者将服务注册到服务注册中心时，将服务名+服务版本号+服务分组作为路由关键信息存放到注册中心，服务消费者在发起服务调用时，除了携带服务名、方法名、参数列表之外，还需要携带要消费的服务版本信息，由路由接口负责服务版本过滤，如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/13_1.png" alt=""></p><h2 id="1-5-服务热升级"><a href="#1-5-服务热升级" class="headerlink" title="1.5 服务热升级"></a>1.5 服务热升级</h2><p>在业务不中断的情况下，实现系统的平滑升级，考虑到版本升级的风险，往往需要做多次滚动升级，最终根据升级之后新版本服务的运行状况决定是继续升级还是回退。这就意味着在同一时刻，整个集群环境中会同时存在服务的多个版本咋线运行，这就是热升级相比于传统 AB Test等升级方式的差异，如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/13_2.png" alt=""><br>核心点如下：</p><ol><li>升级的节点需要重启，由于自动发现机制，停机升级的节点自动被隔离，停机并不会中断业务。</li><li>服务路由规则的定制：如果是滚动式的灰度发布，在相当长的一段时间（例如一周）内线上都会存在服务的多个版本。哪些用户或者业务需要路由到新版本上，需要通过路由策略和规则进行制定，服务框架应该支持用户配置自定义的路由规则来支持灵活的路由策略。</li><li>滚动升级和回退机制：为了降低服务热升级对业务的影响，同时考虑到可靠性，在实际工作中往往采用滚动升级的方式，分批次进行服务的热升级，实现敏捷的特性交付，滚动升级如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/13_3.png" alt=""></li></ol><h1 id="2-与-OSGI-的对比"><a href="#2-与-OSGI-的对比" class="headerlink" title="2 与 OSGI 的对比"></a>2 与 OSGI 的对比</h1><p>OSGI，成立于 1999年，全名原为：Open Services Gateway initiative，但现在这个全名已经废弃。<br>致力于家用设备、汽车、手机、桌面、其它环境指定下一代网络服务标准的领导者，推出了 OSGI 服务平台规范，用于提供开放和通用的架构，使得服务提供商、开发人员、软件提供商、网关操作者和设备提供商以统一的方式开发、部署和管理服务。  </p><p>目前最广泛和应用是 OSGI规范5（Release 5），共由核心规范、标准服务（Standard Services）、框架服务（Framework Services）、系统服务（System Services）、协议服务（Protocol Services）、混合服务（Miscellaneous Services）等几部分共同组成。<br>核心规范通过一个分层的框架，实现了 OSGI最为成功的动态插件机制，它主要提供了：</p><ol><li>OSGI Bundle 的运行环境。</li><li>OSGI Bundle 间的依赖管理。</li><li>OSGI Bundle 的生命周期管理。</li><li>OSGI 服务的动态交互模型。</li></ol><p>OSGI 两个最核心的特性就是模块化和热插拔机制，分布式服务框架的服务多版本管理和热升级是否可以基于 OSGI来实现？下面围绕着模块化和插件热插拔这两个特性进行详细分析。</p><h2 id="2-1-模块化开发"><a href="#2-1-模块化开发" class="headerlink" title="2.1 模块化开发"></a>2.1 模块化开发</h2><p>在 OSGI中，我们以模块化的方式去开发一个系统，每个模块被称为 Bundle，OSGI 提供了对 Bundle的整个生命周期管理，包括打包、部署、运行、升级、停止等。<br>模块化的核心并不是简单地把系统拆分成不同的模块，如果仅仅是拆分，原生的 Jar包+Eclipse工程就能够解决问题。更为重要的是要考虑到模块中接口的导出、隐藏、依赖、版本管理、打包、部署、运行和升级等全生命周期管理，这些对于原生的 Jar包而言是不支持的。<br>传统开发的模块划分通常由两种方式：  </p><ol><li>使用 package来进行隔离。</li><li>定义多个子工程，工程之间通过工程引用的方式进行依赖管理。<br>存在的问题：无法实现资源的精细划分和对依赖做统一管理。以 Jar包依赖为例，依赖一个 Jar包就意味着这个 Jar包中所有 public的资源都可能被引用，但事实上也许只需要依赖该 Jar包中的某几个 public接口。无法对资源做细粒度、精确的管控，不知道 public的接口都被哪些模块依赖和使用，消费者是谁，更为复杂的场景是如果消费者需要依赖不同的接口版本，那该肿么办？  </li></ol><p>OSGI 很好地解决了这个问题，每个 OSGI工程是一个标准的插件工程，实际就是一个 Bundle。实现了 package级的管理依赖关系，而 Maven则是 Jar包级的管理依赖。<br>而分布式服务：</p><ol><li>服务提供者通过 service export将某个服务接口发布出去，供消费者使用。</li><li>服务消费者通过 service import导入某个服务接口，它不关心服务提供者的具体位置，也不关心服务的具体实现细节。<br>这样就比 OSGI的 package导入导出功能粒度更细。<br>利用 Maven的模块化管理 + 分布式服务框架自身的服务接口导入导出功能，解决了模块化开发和精细化依赖管理难题，完成可以替代 OSGI的相关功能，</li></ol><h2 id="2-2-插件热部署和热升级"><a href="#2-2-插件热部署和热升级" class="headerlink" title="2.2 插件热部署和热升级"></a>2.2 插件热部署和热升级</h2><p>OSGI 另外一个非常酷的特性就是动态性，即插件的热部署和热升级，它可以在不重启 JVM的情况下安装部署一个插件，实现升级不中断业务。<br>OSGI 的插件热部署和热升级原理就是基于自身的网状类加载机制实现的，下面我们分析在分布式服务框架中，如何实现服务热部署和热升级：  </p><ol><li>服务是分布式集群部署的，通常也是无状态的，停掉其中某一个服务节点，并不会影响系统整体的运行质量。</li><li>服务自动发现和隔离机制，当有新的服务节点加入时，服务注册中心会向消费者集群推送新的服务地址信息；当有服务节点宕机或重启时，服务注册中心会发送服务下线通知消息给消费者集群，消费者会将下线服务自动隔离。</li><li>优雅停机功能，在进程退出之前，处理完消息队列积压的消息，不再接受新的消息，最大限度保障丢失消息。</li><li>集群容错功能，如果服务提供者正在等待应答消息时系统推出了，消费者会发生服务调用超时，集群容错功能会根据策略重试其它正常的服务节点，保证流程不会因为某个服务实例宕机而中断。</li><li>服务多版本管理，支持集群中同一个服务的多个版本同时运行，支持路由规则定制，不同的消费者可以消费不同的服务版本。</li></ol><p>相比于 OSGI在 JVM内部通过定制类加载机制实现插件的多版本运行和升级，使用分布式服务框架自身的分布式集群特性实现服务的热部署和热升级，更加简单、灵活和可控。</p><h1 id="3-个人总结"><a href="#3-个人总结" class="headerlink" title="3 个人总结"></a>3 个人总结</h1><p>服务多版本在实际项目中非常实用，用于实现服务的热部署和热升级，同时支持按照消费者做差异化路由，同时也方便演进到微服务架构，来迁移到服务的独立打包、部署、运行和运维。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;服务上线之后，由于功能变更、BUG修复，以及服务升级，需要对服务采用多版本管理。&lt;/p&gt;
&lt;h1 id=&quot;1-服务多版本管理设计&quot;&gt;&lt;a href=&quot;#1-服务多版本管理设计&quot; class=&quot;headerlink&quot; title=&quot;1 服务多版本管理设计&quot;&gt;&lt;/a&gt;1 服务多
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>十二、参数传递</title>
    <link href="http://www.liwenguang.cn/2018/06/05/distributed_principle_prictice/12.html/"/>
    <id>http://www.liwenguang.cn/2018/06/05/distributed_principle_prictice/12.html/</id>
    <published>2018-06-05T14:28:00.000Z</published>
    <updated>2018-06-06T13:24:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>服务消费者和提供者之间进行通信时，除了接口定义的请求参数，往往还需要携带一些额外参数，例如消费提供者的 IP地址、消息调用链的跟踪 ID等；这些参数不能通过业务接口来进行传递，需要底层的分布式服务框架支持这种参数传递方式。</p><h1 id="1-内部参数"><a href="#1-内部参数" class="headerlink" title="1 内部参数"></a>1 内部参数</h1><h2 id="1-1-业务内部参数传递"><a href="#1-1-业务内部参数传递" class="headerlink" title="1.1 业务内部参数传递"></a>1.1 业务内部参数传递</h2><ol><li>硬编码，在业务逻辑中进行 API调用，参数通过 API接口进行引用传参。</li><li>业务编排引擎对业务流程进行编排，参数往往通过抽象的编排上下文进行传递。</li><li>通过专业的 BPM流程引擎进行业务逻辑编排，参数通过流程上下文进行传递。</li></ol><p>硬编码通常会直接通过方法参数进行参数传递，如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/12_1.png" alt=""><br>还有一种比较常用的方法就是通过线程上下文进行参数传递。通常情况下业务逻辑处理过程很少发生线程切换，因此通过线程上下文进行隐式传参可以不与某个具体方法接口耦合，对业务解耦接口没有侵入性。例如 Spring 的资源和事务线程绑定机制，利用的就是 JDK 提供的线程上下文。使用线程上下文传参是一种隐式传参，上面的方法调用可以简化成如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/12_2.png" alt=""><br>最后一种方式就是 BPM流程引擎，流程引擎通过流程上下文进行参数传递，用户可以在流程编排界面声明流程级参数和全局参数，流程引擎通过流程上下文进行参数传递。</p><h2 id="1-2-服务框架内部参数擦混地"><a href="#1-2-服务框架内部参数擦混地" class="headerlink" title="1.2 服务框架内部参数擦混地"></a>1.2 服务框架内部参数擦混地</h2><p>服务框架内部由多个模块组成，模块之间的调用通常会发生线程切换；另外，当服务框架通过反射调用服务接口实现类时，也需要向业务代码传递一些额外的参数，这些参数如何传递？下面我们分别对这两类场景进行分析：  </p><ol><li>通信框架将数据报反序列化成业务请求对象之后，需要将消息封装成 Task，丢到后面的业务线程池中执行，此时会发生线程切换，如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/12_4.png" alt="">由于发生了线程切换，如果通过线程变量的方式传递参数，需要遍历线程上下文，将线程变量复制到业务线程池的线程变量中，非常麻烦。如果后续新增系统参数，往往会忘记复制，导致参数不一致。<br>这种场景中，一般会选择通过消息上下文进行参数传递，例如在业务请求参数中定义了 Map 扩展参数，用于跨线程的参数传递。  </li><li>当服务框架回调业务接口实现类时，由于是通过反射调用，业务接口的参数已经定义好了，无法传递其它参数（例如消费者的 IP地址、调用链 ID等参数）。为了解决这个问题，需要利用线程变量，因为平台调用服务实现类不会发生线程切换，所以通过线程变量传参是安全的。</li></ol><h1 id="2-外部参数"><a href="#2-外部参数" class="headerlink" title="2 外部参数"></a>2 外部参数</h1><p>主要用途：</p><ol><li>服务框架自身的参数传递，例如分布式事务中事务上下文信息传递。</li><li>业务之间的参数传递，例如业务调用链 ID的传递，用于唯一表示某个完整业务流程。</li></ol><h2 id="2-1-通信协议支持"><a href="#2-1-通信协议支持" class="headerlink" title="2.1 通信协议支持"></a>2.1 通信协议支持</h2><p>消费者的自定义参数传递到服务端，需要有一个载体，它就是通信协议。一个设计良好的协议，往往支持用户自定义扩展消息头，在协议消息头中，可以预留一个 Map<string, byte[]=""> 类型的字段，用于服务框架或者用户自定义参数扩展。</string,></p><h2 id="2-2-传参接口定义"><a href="#2-2-传参接口定义" class="headerlink" title="2.2 传参接口定义"></a>2.2 传参接口定义</h2><p>服务框架需要提供参数设置 API接口，用于业务跨进程的参数传递。建议使用线程变量，例如平台定义一个 RPCContext 线程变量供业务传参使用。<br>服务框架在业务请求参数传递到通信框架时，需要遍历 RPCContext，将框架和业务设置的参数复制到通信线程中，由通信线程在序列化时将请求参数设置到消息头中，传递到通信对端，如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/12_5.png" alt=""></p><h1 id="3-最佳实践"><a href="#3-最佳实践" class="headerlink" title="3 最佳实践"></a>3 最佳实践</h1><h2 id="3-1-防止参数互相覆盖"><a href="#3-1-防止参数互相覆盖" class="headerlink" title="3.1 防止参数互相覆盖"></a>3.1 防止参数互相覆盖</h2><p>由于使用的是 Map 或线程变量，因此需要防止参数互相覆盖：  </p><ol><li>服务框架系统参数和业务参数的互相覆盖。</li><li>业务之间的参数覆盖。</li></ol><p>一些系统参数往往默认会被平台占用，例如 IP、timeStamp、Host、ServiceName、Group 等常见字段。因此系统平台需要规范，对于业务来说需要有一个全局的业务传参规则。</p><h2 id="3-2-参数声明周期管理"><a href="#3-2-参数声明周期管理" class="headerlink" title="3.2 参数声明周期管理"></a>3.2 参数声明周期管理</h2><p>预防内存泄漏！通常，服务框架能对参数生命周期进行自动管理，例如对于服务端，服务调用前设置参数，服务调用后清空参数。<br>但是对于消费者比较复杂，如果在将参数序列化到请求头发送之后自动清空参数，后续应答返回之后消费者可能需要继续访问之前的参数，但是有可能后续不使用该参数或者忘记删除该参数就会导致参数堆积。如果参数名每次都不同，则会发生内存泄漏。  </p><p>最好的方式就是平台的提供一个删除模式参数的 API，允许用户手动删除，如果用户不指定就自动删除。</p><h1 id="4-个人总结"><a href="#4-个人总结" class="headerlink" title="4 个人总结"></a>4 个人总结</h1><p>参数传递涉及到上下文、通信框架的线程切换、以及自动删除的自动管理等，而服务框架需要提供不同的参数传递模式以适应业务。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;服务消费者和提供者之间进行通信时，除了接口定义的请求参数，往往还需要携带一些额外参数，例如消费提供者的 IP地址、消息调用链的跟踪 ID等；这些参数不能通过业务接口来进行传递，需要底层的分布式服务框架支持这种参数传递方式。&lt;/p&gt;
&lt;h1 id=&quot;1-内部参数&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>十一、服务灰度发布</title>
    <link href="http://www.liwenguang.cn/2018/06/04/distributed_principle_prictice/11.html/"/>
    <id>http://www.liwenguang.cn/2018/06/04/distributed_principle_prictice/11.html/</id>
    <published>2018-06-04T15:51:00.000Z</published>
    <updated>2018-06-05T14:22:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test 就是一种灰度发布方式：让一部分用户继续用 A，一部分用户开始用 B；如果用户对 B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到 B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。</p><h1 id="1-服务灰度发布流程设计"><a href="#1-服务灰度发布流程设计" class="headerlink" title="1 服务灰度发布流程设计"></a>1 服务灰度发布流程设计</h1><p>服务灰度发布的主要作用如下：  </p><ol><li>解决服务升级不兼容问题。</li><li>及早获得用户的意见反馈，完善产品功能，提升服务质量。</li><li>缩小服务升级所影响的用户范围，降低升级风险。</li><li>让用户及早参与产品测试，加强用户互动。</li></ol><h2 id="1-1-灰度环境准备"><a href="#1-1-灰度环境准备" class="headerlink" title="1.1 灰度环境准备"></a>1.1 灰度环境准备</h2><p><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/11_1.png" alt="">  </p><ol><li>系统运维人员通过管理员账号登录灰度发布 Portal或者进入服务治理的灰度发布界面。</li><li>在生产环境中圈定本轮灰度发布的范围，它通常是一个应用集群，包括前后台服务，当然可能是单个服务。</li><li>将选择的服务灰度发布范围信息保存到服务注册中心，用于后续的规则下发和灰度升级历史记录查询等。</li><li>通知灰度升级查询内的服务实例下线，通常会采用优雅停机的方式让待升级的服务下线，保证升级不中断业务。</li><li>应用金城接收到优雅停机指令后，将本进程内缓存的消息处理完，然后优雅退出。</li><li>从软件仓库选择需要升级的服务安装镜像包，用于灰度环境的版本升级。</li><li>将升级包批量上传到灰度环境中，把原来的业务软件包做本地备份之后，升级服务版本。</li><li>灰度环境升级部署成功之后，返回灰度环境部署成功消息给灰度发布管理控制台，然后进行后续的灰度发布操作。</li></ol><h2 id="1-2-灰度规则设置"><a href="#1-2-灰度规则设置" class="headerlink" title="1.2 灰度规则设置"></a>1.2 灰度规则设置</h2><p>灰度环境准备完成之后，运维人员对灰度规则进行配置，灰度规则主要用于服务路由。<br>按照规则的不同，部分用户将调用老的服务，另一部分用户则会调用灰度环境中新发布的服务，常用的灰度规则分类如下：  </p><ol><li>按照接入门户类型分类，例如网上营业厅、手机客户端、营业厅实体店、自主业务办理终端等。</li><li>按照终端类型分类，例如 Android、IOS、Windows Phone 等。</li><li>按照区域进行划分，例如东北、华北、华中等。</li><li>其它策略。</li></ol><p><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/11_2.png" alt=""></p><h2 id="1-3-灰度规则下发"><a href="#1-3-灰度规则下发" class="headerlink" title="1.3 灰度规则下发"></a>1.3 灰度规则下发</h2><p>灰度规则设置完成之后，需要将规则下发给参与消费路由的软负载均衡器 SLB、Web前台和后台服务，它的处理流程如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/11_3.png" alt=""><br>灰度规则下发，主要由服务注册中心负责推送，推送的目标包括前端的 SLB负载均衡器、Web 前台集群和 App 后台服务集群，各节点将灰度规则缓存到本地内存中；消息或者服务路由时，通过路由插件解析灰度规则，将消息路由到指定到服务版本中。需要指出的是，灰度规则的通知范围是整个生产环境集群，包括灰度发布环境和非灰度生产环境。</p><h2 id="1-4-灰度路由"><a href="#1-4-灰度路由" class="headerlink" title="1.4 灰度路由"></a>1.4 灰度路由</h2><p>通过 SLB定制的灰度发布插件，可以将 HTTP消息按照规则分发到不同的 Web前台；Web前台根据内置的服务框架 SDK，通过客户端灰度路由插件，解析灰度规则，将服务路由到灰度或者非灰度环境，实现服务的灰度路由。<br>灰度路由的流程如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/11_4.png" alt=""><br>需要指出的是，如果灰度规则解析失败，实际上就无法区分哪些服务应该路由到灰度环境，这种场景下比较合适的做法就是将服务路由到非灰度环境。如果服务提供者无法处理或者处理失败，则需要对灰度发布做回退处理，并通知所有受影响的服务消费者。</p><h2 id="1-5-失败回滚"><a href="#1-5-失败回滚" class="headerlink" title="1.5 失败回滚"></a>1.5 失败回滚</h2><p>失败回滚的流程如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/11_5.png" alt=""></p><h2 id="1-6-灰度发布总结"><a href="#1-6-灰度发布总结" class="headerlink" title="1.6 灰度发布总结"></a>1.6 灰度发布总结</h2><p>灰度发布之后，需要对灰度发布之后的服务运行和运营情况进行分析，包括服务调用来源分析、服务性能 KPI数据、用户行为分析报告、用户问卷调查等，通过对这些数据进行分析来改进服务功能，完善产品，为新一轮灰度发布做铺垫。</p><h1 id="2-个人总结"><a href="#2-个人总结" class="headerlink" title="2 个人总结"></a>2 个人总结</h1><p>互联网产品在于不停地升级、升级，再升级，但是升级伴随着风险，新旧版本兼容的风险，用户使用习惯突然改变而造成用户流失的风险，系统宕机的风险等。为了避免这些风险，很多产品都采用了灰度发布的策略，其主要思想就是把影响集中到一个点，然后再发散到一个面，出现意外情况后就容易回退。<br>分布式服务框架支持服务的灰度发布，可以实现业务的快速试错和敏捷交付。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test 就是一种灰度发布方式：让一部分用户继续用 A，一部分用户开始用 B；如果用户对 B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到 B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>十、服务发布和引用</title>
    <link href="http://www.liwenguang.cn/2018/06/03/distributed_principle_prictice/10.html/"/>
    <id>http://www.liwenguang.cn/2018/06/03/distributed_principle_prictice/10.html/</id>
    <published>2018-06-03T15:55:00.000Z</published>
    <updated>2018-06-04T15:51:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>服务提供者需要支持通过配置、注解、API调用等方式，把本地接口发布成远程服务；对于消费者，可以通过对等的方式引用远程服务提供者，实现服务的发布和引用。</p><h1 id="1-服务发布设计"><a href="#1-服务发布设计" class="headerlink" title="1 服务发布设计"></a>1 服务发布设计</h1><p>服务发布流程：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/10_1.png" alt=""></p><h2 id="1-1-服务发布的几种方式"><a href="#1-1-服务发布的几种方式" class="headerlink" title="1.1 服务发布的几种方式"></a>1.1 服务发布的几种方式</h2><ol><li>XML配置化方式：业务代码零侵入</li><li>注解方式：业务代码低侵入</li><li>API调用方式：业务代码侵入较强</li></ol><h2 id="1-2-本地实现类封装成代理"><a href="#1-2-本地实现类封装成代理" class="headerlink" title="1.2 本地实现类封装成代理"></a>1.2 本地实现类封装成代理</h2><p>对于服务提供者，将本地实现类封装成代理对象不是必需的：也可以利用一系列工具类解析服务提供者信息，然后将服务提供者的地址信息注册到服务注册中心。采用动态代理的好处如下：  </p><ol><li>不管是什么服务，它们的发布流程都是相似的，通过抽象代理层，可以对服务发布行为本身进行封装和抽象。</li><li>通过动态代理对象，可以对服务发布进行动态拦截，方便平台和业务对服务发布进行个性化定制。</li><li>便于扩展和替换。</li></ol><h2 id="1-3-服务发布成指定协议"><a href="#1-3-服务发布成指定协议" class="headerlink" title="1.3 服务发布成指定协议"></a>1.3 服务发布成指定协议</h2><p>同一个服务，允许发布成多种协议，例如 HTTP、Thrift 等。</p><h2 id="1-4-服务提供者信息注册"><a href="#1-4-服务提供者信息注册" class="headerlink" title="1.4 服务提供者信息注册"></a>1.4 服务提供者信息注册</h2><p>服务按指定协议发布之后，需要将服务发布信息注册到注册中心，用于服务路由和服务治理。  </p><p>服务注册的结构有多种方式，例如按照主机地址、按照服务名或者 URL。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/10_2.png" alt=""></p><h1 id="2-服务引用设计"><a href="#2-服务引用设计" class="headerlink" title="2 服务引用设计"></a>2 服务引用设计</h1><p>消费者导入服务提供者的接口 API定义，配置服务引用信息，即可在代码中直接调用远程服务：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/10_3.png" alt="">  </p><h2 id="2-1-本地接口调用转换成远程服务调用"><a href="#2-1-本地接口调用转换成远程服务调用" class="headerlink" title="2.1 本地接口调用转换成远程服务调用"></a>2.1 本地接口调用转换成远程服务调用</h2><p>原理在于根据导入的服务提供者接口 API和服务引用信息，生成远程服务的本地动态代理对象；它负责将本地的 API调用转换成远程服务调用，然后将结果返回给调用者。</p><h2 id="2-2-服务地址的本地缓存"><a href="#2-2-服务地址的本地缓存" class="headerlink" title="2.2 服务地址的本地缓存"></a>2.2 服务地址的本地缓存</h2><p>服务消费者和提供者的启动顺序无法控制，因此消费者需要检测指定服务目录，监听新的服务提供者注册和已发布服务的下线，工作原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/10_4.png" alt=""></p><h2 id="2-3-远程服务调用"><a href="#2-3-远程服务调用" class="headerlink" title="2.3 远程服务调用"></a>2.3 远程服务调用</h2><p>消费者从本地缓存的服务列表中按照指定策略路由，将请求消息封装成协议消息：调用相关协议的客户端将请求发送给服务提供者，业务线程按照服务调用方式选择同步等待或者注册监听器回调。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/10_5.png" alt=""></p><h1 id="3-最佳实践"><a href="#3-最佳实践" class="headerlink" title="3 最佳实践"></a>3 最佳实践</h1><h2 id="3-1-对等设计原则"><a href="#3-1-对等设计原则" class="headerlink" title="3.1 对等设计原则"></a>3.1 对等设计原则</h2><p>例如，通过 XML的 Method 元素可以配置方法级参数，那么 API或者注解也应该支持方法级设置，以防止能力不对等。</p><h2 id="3-2-启动顺序问题"><a href="#3-2-启动顺序问题" class="headerlink" title="3.2 启动顺序问题"></a>3.2 启动顺序问题</h2><p>服务注册中心如果后启动，需要服务提供者和消费者能够自动重连。</p><h2 id="3-3-同步还是异步发布服务"><a href="#3-3-同步还是异步发布服务" class="headerlink" title="3.3 同步还是异步发布服务"></a>3.3 同步还是异步发布服务</h2><p>通常情况下，服务全部准备就绪的时间比较短，而且系统启动之后也并不意味着所有服务都会被立即消费，因此，采用异步的方式发布服务也是可行的。<br>当然还有另外一些办法可减少系统启动时间。例如对于不经常访问的服务采用延迟发布的策略；还有就是服务的懒加载，只发布服务但是不初始化，等到消费者真正调用的时候才进行初始化服务。</p><h2 id="3-4-警惕网络风暴"><a href="#3-4-警惕网络风暴" class="headerlink" title="3.4 警惕网络风暴"></a>3.4 警惕网络风暴</h2><p>在大规模集群系统中，服务注册中心可能管理数十万条的服务注册信息以及上万个服务提供者和消费者节点。如果服务注册中心管理了大量经常变更的信息，就会发生频繁的变更通知：而这种海量的变更通知可能会挤占服务注册中心的网络带宽，严重时还会导致网络风暴。<br>因此，在设计时需要考虑如下几个要素：  </p><ol><li>哪些信息需要注册到服务注册中心，需要甄别。</li><li>服务注册中心能够管理的服务上限。</li><li>服务注册中心的网络带宽规划。</li><li>服务注册中心的磁盘空间规划。</li><li>服务注册中心的性能。</li></ol><h2 id="3-5-配置扩展"><a href="#3-5-配置扩展" class="headerlink" title="3.5 配置扩展"></a>3.5 配置扩展</h2><h1 id="4-个人总结"><a href="#4-个人总结" class="headerlink" title="4 个人总结"></a>4 个人总结</h1><p>好的分布服务框架对业务代码的侵入要足够低（使用 XML配置方式），将普通的 Java 接口发布成远程服务。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;服务提供者需要支持通过配置、注解、API调用等方式，把本地接口发布成远程服务；对于消费者，可以通过对等的方式引用远程服务提供者，实现服务的发布和引用。&lt;/p&gt;
&lt;h1 id=&quot;1-服务发布设计&quot;&gt;&lt;a href=&quot;#1-服务发布设计&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>九、服务注册中心</title>
    <link href="http://www.liwenguang.cn/2018/06/02/distributed_principle_prictice/9.html/"/>
    <id>http://www.liwenguang.cn/2018/06/02/distributed_principle_prictice/9.html/</id>
    <published>2018-06-02T04:10:00.000Z</published>
    <updated>2018-06-02T04:10:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-几个概念"><a href="#1-几个概念" class="headerlink" title="1 几个概念"></a>1 几个概念</h1><h2 id="1-1-服务提供者"><a href="#1-1-服务提供者" class="headerlink" title="1.1 服务提供者"></a>1.1 服务提供者</h2><h2 id="1-2-服务消费者"><a href="#1-2-服务消费者" class="headerlink" title="1.2 服务消费者"></a>1.2 服务消费者</h2><h2 id="1-3-服务注册中心"><a href="#1-3-服务注册中心" class="headerlink" title="1.3 服务注册中心"></a>1.3 服务注册中心</h2><p>服务注册中心是分布式服务框架的目录服务器，相比于传统的目录服务器，它有如下几个特点：  </p><ol><li>高 HA：支持数据持久化、支持集群。</li><li>数据一致性问题：集群中所有的客户端应该看到同一份数据，不能出现读或者写数据不一致。</li><li>数据变更主动推送：当注册中心的数据发生变更时（增加、删除、修改）需要能够及时将变化的数据通知给客户端。</li></ol><h1 id="2-关键功能特性设计"><a href="#2-关键功能特性设计" class="headerlink" title="2 关键功能特性设计"></a>2 关键功能特性设计</h1><p>服务注册中心的工作原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/9_1.png" alt="">  </p><ol><li>服务提供者在启动时，根据服务发布文件中配置的服务发布信息向注册中心注册自己提供的服务。</li><li>服务消费者在启动时，根据消费者配置文件中配置的服务消费信息向注册中心订阅自己所需的服务，消费者刷新本地缓存的路由表。</li><li>注册中心返回服务提供者地址列表，如果有变更，注册中心主动推送变更数据给消费者，消费者刷新本地缓存的路由表。</li><li>服务消费者从本地缓存的服务提供者地址列表中，基于负载均衡算法选择一台服务提供者进行调用。</li></ol><h2 id="2-1-支持对等集群"><a href="#2-1-支持对等集群" class="headerlink" title="2.1 支持对等集群"></a>2.1 支持对等集群</h2><p>服务注册中心需要支持对等集群，如下图，其中某一个或者多个服务注册中心进程宕机，不会导致服务注册中心集群功能不可用。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/9_2.png" alt=""><br>对于客户端，无论服务注册中心集群配置多少个进程，客户端只需要连接其中某一个即可（服务端之间自己进行数据同步），如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/9_3.png" alt=""></p><h2 id="2-2-提供-CRUD-接口"><a href="#2-2-提供-CRUD-接口" class="headerlink" title="2.2 提供 CRUD 接口"></a>2.2 提供 CRUD 接口</h2><p>客户端连接服务注册中心之后，需要能够对服务注册中心的数据进行操作：</p><ol><li>查询接口：查询系统当前发布的服务信息和订阅的消费者信息。</li><li>修改接口：修改已经发布的服务属性或者消费者属性信息，通常用于运行态的服务治理。</li><li>新增接口：发布或者订阅新的服务。</li><li>删除接口：去注册已经发布的服务，或者消费者取消订阅关系。</li></ol><h2 id="2-3-安全加固"><a href="#2-3-安全加固" class="headerlink" title="2.3 安全加固"></a>2.3 安全加固</h2><p>服务注册中心需要进行安全加固，安全加固主要涉及两部分：  </p><ol><li>链路的安全性。</li><li>数据的安全性。</li></ol><p>链路的安全性指的是服务注册中心对客户端连接进行安全认证，认证策略非常多，最简单的就是基于 IP地址的黑名单校验，更加复杂的有基于用户名+密码的认证，或者基于秘钥+数字证书的认证。<br>认证失败，则关闭链路，拒绝客户端连接。  </p><p>数据的安全性主要针对服务注册中心的数据进行权限控制：  </p><ol><li>非授权客户端既不能读取也不能写入数据。</li><li>普通运维人员只能读取数据，不能修改数据。</li><li>管理员既可以读取也可以修改数据。</li><li>不同的服务目录可以设置不同的访问权限，例如消费者只能查看它所在机房的服务。数据安全性工作原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/9_4.png" alt=""></li></ol><h2 id="2-4-订阅发布机制"><a href="#2-4-订阅发布机制" class="headerlink" title="2.4 订阅发布机制"></a>2.4 订阅发布机制</h2><p>对于服务提供者，可以根据服务名等信息动态发布服务；对于消费者，可以根据订阅关系主动获得服务发布者的地址信息等。订阅发布机制还有一个比较重要的机制就是对变化的监听和主动推送能力：</p><ol><li>消费者可以监听一个或者多个服务目录，当目录名称、内容发生变更时，消费者可以实时地获得变更的数据或者变更后的结果信息。</li><li>服务提供者可以发布一个或者多个服务，动态修改服务名称、服务内容等，可以主动将修改后的数据或者修改后的结果推送给所有监听此服务目录的消费者。<br>订阅发布机制有如下优点：  </li><li>透明化路由：服务提供者和消费者互相解耦，服务提供者未知透明，消费者不需要再硬编码服务提供者地址。</li><li>服务健康状态监测：服务注册中心可以实时监测发布服务的质量，如果服务提供者宕机，由服务注册中心实时通知消费者。</li><li>弹性伸缩能力（动态发现）：应用在云端部署之后，由于 VM资源占用率过高，动态伸展出一个新的服务提供者，服务注册中心会将新增的服务提供者地址信息推送给消费者，消费者刷新本地路由表之后可以访问新的服务提供者，实现服务的弹性伸缩。</li></ol><h2 id="2-3-可靠性"><a href="#2-3-可靠性" class="headerlink" title="2.3 可靠性"></a>2.3 可靠性</h2><p>服务注册中心需要支持对等集群，任意一台宕机后，服务都能自动切换到其它正常的服务注册中心。<br>如果服务注册中心全部宕机，只影响新的服务注册、已发布服务的下线。（想想为什么）<br>服务提供者的健康状态监测也由服务注册中心负责监测，通过长连接心跳检测服务提供者的存在，宕机则实时推送消息，实现实时故障隔离。</p><h1 id="3-基于-ZooKeeper-的服务注册中心设计"><a href="#3-基于-ZooKeeper-的服务注册中心设计" class="headerlink" title="3 基于 ZooKeeper 的服务注册中心设计"></a>3 基于 ZooKeeper 的服务注册中心设计</h1><h2 id="3-1-服务订阅发布流程设计"><a href="#3-1-服务订阅发布流程设计" class="headerlink" title="3.1 服务订阅发布流程设计"></a>3.1 服务订阅发布流程设计</h2><p>流程设计如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/9_5.png" alt=""></p><h2 id="3-2-服务健康状态监测"><a href="#3-2-服务健康状态监测" class="headerlink" title="3.2 服务健康状态监测"></a>3.2 服务健康状态监测</h2><p>基于 ZK 客户端和服务端的长连接和会话超时控制机制，来实现服务健康状态监测。</p><h2 id="3-3-对等集群防止单点故障"><a href="#3-3-对等集群防止单点故障" class="headerlink" title="3.3 对等集群防止单点故障"></a>3.3 对等集群防止单点故障</h2><p>ZK 使用了原子广播（恢复服务和广播服务）实现故障转移以及同步。</p><h1 id="4-个人总结"><a href="#4-个人总结" class="headerlink" title="4 个人总结"></a>4 个人总结</h1><p>服务注册中心要保证可靠性、安全性、可扩展性。ZK 是常用的技术。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-几个概念&quot;&gt;&lt;a href=&quot;#1-几个概念&quot; class=&quot;headerlink&quot; title=&quot;1 几个概念&quot;&gt;&lt;/a&gt;1 几个概念&lt;/h1&gt;&lt;h2 id=&quot;1-1-服务提供者&quot;&gt;&lt;a href=&quot;#1-1-服务提供者&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>2018.06.09 同学聚会</title>
    <link href="http://www.liwenguang.cn/2018/06/01/talker/schoolmate01.html/"/>
    <id>http://www.liwenguang.cn/2018/06/01/talker/schoolmate01.html/</id>
    <published>2018-06-01T15:00:00.000Z</published>
    <updated>2018-06-01T15:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th style="text-align:center">序号</th><th style="text-align:center">名</th><th style="text-align:center">达到日期</th><th style="text-align:center">起始时间</th><th style="text-align:center">起始地点</th><th style="text-align:center">车次号</th><th style="text-align:center">婚育概要</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">陈佳慧</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">全天</td><td style="text-align:center">南京~南京</td><td style="text-align:center">无</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">孔令洲</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">全天</td><td style="text-align:center">南京~南京</td><td style="text-align:center">无</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">高帅星</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">全天</td><td style="text-align:center">南京~南京</td><td style="text-align:center">无</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">蒋鑫</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">全天</td><td style="text-align:center">南京~南京</td><td style="text-align:center">无</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">王雨木</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">16:10~18:45</td><td style="text-align:center">长春~南京禄口</td><td style="text-align:center">DZ6258</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">黄菡璐</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">20:09~22:10</td><td style="text-align:center">义乌~南京南</td><td style="text-align:center">G1504</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">谢飘飘</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">20:42~22:10</td><td style="text-align:center">杭州东~南京南</td><td style="text-align:center">G1504</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">陈圳</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">18:39~22:12</td><td style="text-align:center">汉口~南京南</td><td style="text-align:center">D2374</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">吴琦薇</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">20:35~22:27</td><td style="text-align:center">上海~南京南</td><td style="text-align:center">G7286</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">李文广</td><td style="text-align:center">2018-06-08</td><td style="text-align:center">20:35~22:27</td><td style="text-align:center">上海~南京南</td><td style="text-align:center">G7286</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">孙任</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center">李婷婷</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">未婚</td></tr><tr><td style="text-align:center">13</td><td style="text-align:center">黄璐菡</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">？</td><td style="text-align:center">未婚</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;序号&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;名&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;达到日期&lt;/th&gt;
&lt;th 
      
    
    </summary>
    
      <category term="闲聊" scheme="http://www.liwenguang.cn/categories/%E9%97%B2%E8%81%8A/"/>
    
    
  </entry>
  
  <entry>
    <title>八、服务调用</title>
    <link href="http://www.liwenguang.cn/2018/05/31/distributed_principle_prictice/8.html/"/>
    <id>http://www.liwenguang.cn/2018/05/31/distributed_principle_prictice/8.html/</id>
    <published>2018-05-31T15:34:00.000Z</published>
    <updated>2018-06-02T04:10:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>由于惯性思维，很多人会将传统 MVC架构/RPC架构的做法带入到分布式服务框架的架构设计中，其中有些思想存在误区，或者已经过时，它们会破坏分布式服务框架的架构品质。</p><h1 id="1-几个误区"><a href="#1-几个误区" class="headerlink" title="1 几个误区"></a>1 几个误区</h1><h2 id="1-1-NIO-就是异步服务"><a href="#1-1-NIO-就是异步服务" class="headerlink" title="1.1 NIO 就是异步服务"></a>1.1 NIO 就是异步服务</h2><p>NIO 只解决了通信层面的异步问题，跟服务调用的异步没有必然关系，也就是说，即便采用传统的 BIO 通信，依然可以实现异步服务调用，只不过通信效率和可靠性比较差。<br>下面对异步服务调用和通信框架的关系进行说明：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/8_1.png" alt=""><br>用户发起远程服务调用之后，经历层层业务逻辑处理、消息编码，最终序列化后的消息会被放入到通信框架的消息队列中。业务线程可以选择同步等待、也可以选择直接返回，通过消息队列的方式实现业务层和通信层的分离是比较成熟、典型的做法。<br>采用 NIO还是 BIO对上层的业务是不可见的，双方的汇聚点就是消息队列。业务线程将消息放入到发送队列中，可以选择主动等待或者立即返回，跟通信框架是否是 NIO 没有任何关系。</p><h2 id="1-2-服务调用天生就是同步的"><a href="#1-2-服务调用天生就是同步的" class="headerlink" title="1.2 服务调用天生就是同步的"></a>1.2 服务调用天生就是同步的</h2><p>服务调用主要有两种模式：</p><ol><li>OneWay 模式：只有请求，没有应答，例如通知消息。</li><li>请求-应答模式：一请求，一应答的模式，这种模式最常用。</li></ol><p>OneWay 模式的服务调用由于不需要返回应答，因此很容易被设计成异步的：消费者发起远程服务调用之后，立即返回，不需要同步阻塞等待应答。<br>对于请求-应答模式，可以利用 Future-Listener 机制来实现异步服务调用。从业务角度看，它的效果与同步等待等价，但是从技术角度来看，可以保证业务线程在不同步阻塞的情况下实现同步等待的效果，执行效率更高。</p><h2 id="1-3-异步服务调用性能更高"><a href="#1-3-异步服务调用性能更高" class="headerlink" title="1.3 异步服务调用性能更高"></a>1.3 异步服务调用性能更高</h2><p>复杂的场景，异步服务调用会更高，越复杂的场景，异步服务调用优势越大。</p><h1 id="2-服务调用方式"><a href="#2-服务调用方式" class="headerlink" title="2 服务调用方式"></a>2 服务调用方式</h1><h2 id="2-1-同步服务调用"><a href="#2-1-同步服务调用" class="headerlink" title="2.1 同步服务调用"></a>2.1 同步服务调用</h2><p>没什么可说的，只是需要注意设置用户线程等待超时时间。</p><h2 id="2-2-异步服务调用"><a href="#2-2-异步服务调用" class="headerlink" title="2.2 异步服务调用"></a>2.2 异步服务调用</h2><p>基于 JDK的 Future机制，异步服务调用的工作原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/8_2.png" alt="">  </p><ol><li>消费者调用服务端发布的接口，接口调用由分布式服务框架包装成动态代理，发起远程服务调用。</li><li>通信框架异步发送请求消息，如果没有发生 I/O异常，返回。</li><li>请求消息发送成功后，I/O 线程构造 Future 对象，设置到 RPC上下文中。</li><li>用户线程通过 RPC上下文获取 Future对象。</li><li>构造 Listener 对象，将其添加到 Future中，用于服务端应答异步回调通知。</li><li>用户线程返回，不阻塞等待应答，</li><li>服务端返回应答消息，通信框架负责反序列化等。</li><li>I/O 线程将应答设置到 Future 对象的操作结果中。</li><li>Future 对象扫描注册的监听器列表，循环调用监听器的 operationComplete方法，将结果通知给监听器，监听器获取到结果，执行后续业务，异步调用结束。</li></ol><p>还有一种异步调用形式，就是不添加 Listener，用户连续发起 N次服务调用，然后依次从 RPC上下文中获取 Futrue对象，最终再主动 get结果，业务线程阻塞，相对比老的同步服务调用，它的阻塞时间更短，工作原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/8_3.png" alt="">  </p><p>其串行到并行的优化原理如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/8_4.png" alt=""><br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/8_5.png" alt="">  </p><p>异步服务调用的代码示例如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">XxxService1.xxxMethod(Req); <span class="comment">// 立即返回 null</span></div><div class="line">Future f1 = RpcContext.getContext().getFuture();</div><div class="line">XxxService2.xxxMethod(Req);</div><div class="line">Future f2 = RpcContext.getContext().getFuture();</div><div class="line">Object xResult1 = f1.get(<span class="number">3000</span>);</div><div class="line">Object xResult2 = f2.get(<span class="number">3000</span>);</div></pre></td></tr></table></figure></p><p>第二种基于 Future-Listener 的纯异步服务调用示例如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">XxxService1.xxxMethod(Req);</div><div class="line">Future f1 = RpcContext.getContext().getFuture();</div><div class="line">Listener l = <span class="keyword">new</span> Listener();</div><div class="line">f1.addListener(l);</div></pre></td></tr></table></figure></p><h2 id="2-3-并行服务调用"><a href="#2-3-并行服务调用" class="headerlink" title="2.3 并行服务调用"></a>2.3 并行服务调用</h2><p>A服务-&gt;B服务-&gt;C服务-&gt;…<br>串行服务调用比较简单，但在一些业务场景中，需要采用并行服务调用来降低 E2E 的时延。</p><ol><li>多个服务之间逻辑不存在互相依赖关系，执行先后顺序没有严格的要求，逻辑上可以被并行执行。</li><li>长流程业务，调用多个服务，对时延比较敏感，其中有部分服务逻辑上无上下文关联。目标主要有两个：</li><li>降低业务 E2E 时延。</li><li>提升整个系统的吞吐量。</li></ol><h2 id="2-4-泛化调用"><a href="#2-4-泛化调用" class="headerlink" title="2.4 泛化调用"></a>2.4 泛化调用</h2><p>主要用于客户端没有API 接口及数据模型的场景，使用 Map表示。</p><h1 id="3-最佳实践"><a href="#3-最佳实践" class="headerlink" title="3 最佳实践"></a>3 最佳实践</h1><p>服务框架支持多种服务调用方式，在实现项目中中如何选择，建议从以下几个角度考虑：  </p><ol><li>降低业务 E2E时延：业务调用链是否太长、某些服务是否不太可靠，需要对服务调用流程进行梳理，看是否可以通过并行服务调用来提升调用效率，降低服务调用时延。</li><li>可靠性角度：某些业务调用链上的关键服务不太可靠，一旦出故障会导致大量线程资源被挂住，可以考虑使用异步服务调用防止故障扩展。</li><li>业务场景：对于测试，不想为每个测试用例都开发一个服务接口，能否做一个通用的测试框架，通过 Map等泛容器实现通用服务调用。</li><li>传统的 RPC调用：服务调用比较简单，对时延要求不高的场景，可以考虑同步服务调用。</li></ol><h1 id="4-个人总结"><a href="#4-个人总结" class="headerlink" title="4 个人总结"></a>4 个人总结</h1><p>服务调用有多种形式，需要从业务和技术做出取舍。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;由于惯性思维，很多人会将传统 MVC架构/RPC架构的做法带入到分布式服务框架的架构设计中，其中有些思想存在误区，或者已经过时，它们会破坏分布式服务框架的架构品质。&lt;/p&gt;
&lt;h1 id=&quot;1-几个误区&quot;&gt;&lt;a href=&quot;#1-几个误区&quot; class=&quot;headerlin
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>七、集群容错</title>
    <link href="http://www.liwenguang.cn/2018/05/30/distributed_principle_prictice/7.html/"/>
    <id>http://www.liwenguang.cn/2018/05/30/distributed_principle_prictice/7.html/</id>
    <published>2018-05-30T15:14:06.000Z</published>
    <updated>2018-05-31T15:34:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>集群服务调用失败后，服务框架需要能够在底层自动容错。</p><h1 id="1-集群容错场景"><a href="#1-集群容错场景" class="headerlink" title="1 集群容错场景"></a>1 集群容错场景</h1><p>在分布式服务框架中，业务消费者不需要了解服务提供者的具体未知，它发起的服务调用请求也不包含服务提供者具体地址信息。因此，某个服务提供者是否可用对消费者而言无关紧要，最终的服务调用成功才是最重要的。<br>经过服务路由之后，选定某个服务提供者进行远程服务调用，但是服务调用可能会出错，下面进行故障场景进行分析。</p><h2 id="1-1-通信链路故障"><a href="#1-1-通信链路故障" class="headerlink" title="1.1 通信链路故障"></a>1.1 通信链路故障</h2><p>这里的链路指的是消费者和服务提供者之间的链路（通常为长连接），可能导致链路中断的原因有：  </p><ol><li>通信过程中，对方突然宕机导致链路中断。</li><li>通信过程中，对方因为解码失败等原因 Rest 掉连接，导致链路中断。</li><li>通信过程中，消费者 write SocketChannel 发生 IOException 导致链路中断。</li><li>通信过程中，消费者 read SocketChannel 发生 IOException 导致链路中断。</li><li>通信双方因为心跳超时，主动 close SocketChannel 导致链路中断。</li><li>通信过程中，网络发生闪断故障。</li><li>通信过程中，交换机异常导致链路中断。</li><li>通信过程中，消费者或者服务提供者因为长时间 Full GC 导致链路中断。</li></ol><h2 id="1-2-服务端超时"><a href="#1-2-服务端超时" class="headerlink" title="1.2 服务端超时"></a>1.2 服务端超时</h2><ol><li>服务端的 I/O 线程没有及时从网络中读取客户端请求消息，导致该问题的原因通过是 I/O 线程被意外阻塞或者执行长周期操作。</li><li>服务端业务处理缓慢，或者被长时间阻塞，例如查询数据库，由于没有索引导致全表查询，耗时较长。</li><li>服务端发生长时间 Full GC，导致所有业务线程暂停运行，无法及时返回应答给客户端。</li></ol><h2 id="1-3-服务端调用失败"><a href="#1-3-服务端调用失败" class="headerlink" title="1.3 服务端调用失败"></a>1.3 服务端调用失败</h2><ol><li>服务端解码失败，返回消息解码失败异常。</li><li>服务端发生动态流控，返回流控异常。</li><li>服务端消息队列积压率超过最大阈值，返回系统阻塞异常。</li><li>访问权限校验失败，返回权限相关异常。</li><li>违反 SLA 策略，返回 SLA 控制相关异常。</li><li>其它系统异常。</li></ol><p>服务调用异常不包括业务层面的处理异常，例如数据库操作异常、用户记录不存在等异常。</p><h1 id="2-容错策略"><a href="#2-容错策略" class="headerlink" title="2 容错策略"></a>2 容错策略</h1><p>服务不同，容错策略往往也不同，下面是集群容错和服务路由的关系：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/7_1.png" alt=""><br>消费者根据配置的路由策略选择某个目标地址之后，发起远程服务调用，发起远程服务调用，在此期间如果发生了远程服务调用异常，则需要服务框架进行集群容错，重新进行选路和调用。集群容错是系统自动执行的，上层用户并不需要关心底层的服务调用过程。</p><h2 id="2-1-失败自动切换（FailOver）"><a href="#2-1-失败自动切换（FailOver）" class="headerlink" title="2.1 失败自动切换（FailOver）"></a>2.1 失败自动切换（FailOver）</h2><p>服务调用失败自动切换策略指的是当发生 RPC调用异常时，重新选路，查找下一个可用的服务提供者。<br>服务发布的时候，可以指定服务的集群容错策略。消费者可以覆盖服务提供者的通用配置，实现个性化的容错策略。  </p><p>FailOver 策略的设计思路如下：消费者路由操作完成之后，获得目标地址，调用通信框架的消息发送接口发送请求，监听服务端应答。如果返回的结果是 RPC调用异常（超时、流控、解码失败等系统异常），根据消费者集群容错的策略进行容错路由，如果是 FailOver，则重新返回到路由 Handler 的入口，从路由节点继续执行。选录完成之后，对目标地址进行对比，防止重新路由到故障服务节点，过滤掉上次的故障服务提供者之后，调用通信框架的消息发送接口发送请求消息。  </p><ul><li>读操作，因为通常它是幂等的。</li><li>幂等性服务，保证调用1 次和 N 次效果相同。注意：失败重试会增加服务调用时延，因此框架必须对失败重试的最大次数做限制，通常默认为 3，防止无限制重试导致服务调用时延不可控。</li></ul><h2 id="2-2-失败通知（Failback）"><a href="#2-2-失败通知（Failback）" class="headerlink" title="2.2 失败通知（Failback）"></a>2.2 失败通知（Failback）</h2><p>适用于非幂等性的服务调用，通过对失败错误码等异常信息的判断，决定后续的执行策略。<br>Failback 的设计方案如下：服务框架获取到服务提供者返回的 RPC 异常响应之后，根据策略进行容错。将 RPC异常通知给消费者，由消费者捕获异常进行后续处理。</p><h2 id="2-3-失败缓存（Failcache）"><a href="#2-3-失败缓存（Failcache）" class="headerlink" title="2.3 失败缓存（Failcache）"></a>2.3 失败缓存（Failcache）</h2><p>Failcache 策略是失败自动恢复的一种，应用场景如下：</p><ol><li>服务有状态路由，必须定点发送到指定的服务提供者。当发生链路中断、流控等服务暂时不可用时，服务框架将消息临时缓存起来，等待周期T，重新发送，直到服务提供者能够正常处理该消息。</li><li>对时延要求不敏感的服务。系统服务调用失败，通常是链路暂时不可用、服务流控、GC 挂住服务提供者进程等，这种失败不是永久性的失败，它的恢复是可预期的。如果消费者对服务调用时延不敏感，可以考虑采用自动恢复模式，即先缓存，再等待，最后重试。</li><li>通知类服务。例如通知粉丝积分增长、记录接口日志等，对服务调用的实时性要求不高，可以容忍自动恢复带来的时延增加。  </li></ol><p>为了保证可靠性，Failcache 策略在设计的时候需要考虑如下几个要素：</p><ol><li>缓存时间、缓存对象上限数等需要做出限制，防止内存溢出。</li><li>缓存淘汰算法的选择，是否支持用户配置。</li><li>定时重试的周期T、重试的最大次数等需要做出限制并支持用户指定。重试达到最大上限仍失败，需要丢弃消息，记录异常日志。</li></ol><h2 id="2-4-快速失败（Failfast）"><a href="#2-4-快速失败（Failfast）" class="headerlink" title="2.4 快速失败（Failfast）"></a>2.4 快速失败（Failfast）</h2><p>在业务高峰期，对于一些非核心的服务，希望只调用一次，失败也不再重试，为重要的核心服务解约宝贵的运行资源。此时，快速失败是不错的选择。原理在于，获取服务调用异常之后，直接忽略异常，记录异常日志。</p><h2 id="2-5-容错策略扩展"><a href="#2-5-容错策略扩展" class="headerlink" title="2.5 容错策略扩展"></a>2.5 容错策略扩展</h2><p>无论默认支持多少种容错策略，在业务实际使用过程中都需要支持用户自定义扩展容错策略。</p><h1 id="3-个人总结"><a href="#3-个人总结" class="headerlink" title="3 个人总结"></a>3 个人总结</h1><p>集群容错虽然功能简单，设计也并不复杂（不复杂？？？），但是该特性却非常重要。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;集群服务调用失败后，服务框架需要能够在底层自动容错。&lt;/p&gt;
&lt;h1 id=&quot;1-集群容错场景&quot;&gt;&lt;a href=&quot;#1-集群容错场景&quot; class=&quot;headerlink&quot; title=&quot;1 集群容错场景&quot;&gt;&lt;/a&gt;1 集群容错场景&lt;/h1&gt;&lt;p&gt;在分布式服务框架中，业务
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>六、服务路由</title>
    <link href="http://www.liwenguang.cn/2018/05/29/distributed_principle_prictice/6.html/"/>
    <id>http://www.liwenguang.cn/2018/05/29/distributed_principle_prictice/6.html/</id>
    <published>2018-05-29T14:58:00.000Z</published>
    <updated>2018-05-30T15:14:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>分布式服务框架上线运行时都是集群组网，这意味着急群众存在某个服务的多实例部署，消费者如何从服务列表中选择合适的服务提供者进行调用，这就涉及到服务路由。</p><h1 id="1-透明化路由"><a href="#1-透明化路由" class="headerlink" title="1 透明化路由"></a>1 透明化路由</h1><h2 id="1-1-基于服务注册中心的订阅发布"><a href="#1-1-基于服务注册中心的订阅发布" class="headerlink" title="1.1 基于服务注册中心的订阅发布"></a>1.1 基于服务注册中心的订阅发布</h2><p>在分布式服务框架中，服务注册中心用于存储服务提供者地址信息、服务发布相关的属性信息，消费者通过主动查询和被动通知的方式获取服务提供者的地址信息，而不需要像之前那样在代码中硬编码服务提供者地址信息。消费者只需要知道当前系统发布了哪些服务，而不需要知道服务具体存在于什么位置，这就是透明化路由。它的工作原理就是基于服务注册中心（例如 ZooKeeper）的订阅发布机制。<br>服务注册中心的工作原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/6_1.png" alt="">  </p><p>由于消费者可能由于服务提供者启动，或者系统运行过程中新增服务提供者，或者某个服务提供者宕机退出，就会导致注册中心发生服务提供者地址变更。注册中心检测到服务提供者列表变更之后，将变更内容主动推送到服务消费者，消费者根据变更列表，动态刷新本地缓存的服务提供者地址。</p><h2 id="1-2-消费者缓存服务提供者地址"><a href="#1-2-消费者缓存服务提供者地址" class="headerlink" title="1.2 消费者缓存服务提供者地址"></a>1.2 消费者缓存服务提供者地址</h2><p>采用客户端缓存服务提供者地址的方案不仅仅能提升服务调用性能，还能保证系统的可靠性。当注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存的地址信息进行通信，只是影响新服务的注册和老服务的下线，不影响已经发布和运行的服务。</p><h1 id="2-负载均衡"><a href="#2-负载均衡" class="headerlink" title="2 负载均衡"></a>2 负载均衡</h1><h2 id="2-1-随机"><a href="#2-1-随机" class="headerlink" title="2.1 随机"></a>2.1 随机</h2><p>缺点：  </p><ol><li>在一个截面上碰撞的概率较高。</li><li>非对等集群组网，或者硬件配置差异较大，会导致各节点负载均匀。</li></ol><h2 id="2-2-轮询"><a href="#2-2-轮询" class="headerlink" title="2.2 轮询"></a>2.2 轮询</h2><p>轮询，按公约后的权重设置轮询比率，到达边界之后，继续绕接。缺点：  </p><ol><li>存在慢的提供者累计请求问题，例如第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。</li></ol><h1 id="2-3-服务调用时延"><a href="#2-3-服务调用时延" class="headerlink" title="2.3 服务调用时延"></a>2.3 服务调用时延</h1><p>消费者缓存所有服务提供者的服务调用时延，周期性的计算服务调用平均时延，然后计算每个服务提供者服务调用时延与平均时延的差值，根据差值大小动态调整权重，保证服务时延大的服务提供者接收更少的消息，防止消息堆积，  </p><p>该策略的特点就是要保证处理能力强的服务提供者接收到更多的消息，通过动态自动权重调整消除服务调用时延的振荡范围，使所有服务提供者服务调用时延接近平均值，实现负载均衡。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/6_2.png" alt=""> <img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/6_3.png" alt=""></p><h1 id="2-4-一致性哈希"><a href="#2-4-一致性哈希" class="headerlink" title="2.4 一致性哈希"></a>2.4 一致性哈希</h1><p>相同参数的请求总是发到同一个服务提供者，当某一台提供者宕机时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。平台提供默认的虚拟节点数，可以通过配置参数进行修改。<br>一致性 Hash 环工作原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/6_4.png" alt=""></p><h1 id="2-5-粘滞连接"><a href="#2-5-粘滞连接" class="headerlink" title="2.5 粘滞连接"></a>2.5 粘滞连接</h1><p>粘滞连接用于有状态服务，尽可能让客户端总是向同一提供者发起服务调用，除非该提供者宕机，再连接另一台。由于服务通常被强烈建议设计成无状态的，因此，粘滞连接在实际项目中很少使用。<br>粘滞连接的实现比较简单，客户端首次跟服务端创建链路时，将该链路标记为粘滞连接，每次路由时直接选择粘滞连接，不执行负载均衡路由接口，当链路中断时，更新粘滞连接为不可用，重新寻找下一个可用的连接，将其标记为粘滞连接。</p><h1 id="3-本地路由优先策略"><a href="#3-本地路由优先策略" class="headerlink" title="3 本地路由优先策略"></a>3 本地路由优先策略</h1><h2 id="3-1-injvm-模式"><a href="#3-1-injvm-模式" class="headerlink" title="3.1 injvm 模式"></a>3.1 injvm 模式</h2><p>在一些业务场景中，本地 JVM 内部也发布了需要消费的服务。该场景下，从性能、可靠性等角度考虑，需要优先调用本 JVM内部的服务提供者，这种本地优先的路由模式被称为 injvm模式。</p><h2 id="3-2-innative-模式"><a href="#3-2-innative-模式" class="headerlink" title="3.2 innative 模式"></a>3.2 innative 模式</h2><p>如果物理机或者 VM配置较好，多个应用金城往往会选择合设。服务消费者和服务提供者可能会被部署到同一台机器上（VM）。服务路由时优先选择本机的服务提供者，如果找不到再重新发起远程服务调用，该模式被称为 innative模式。</p><ol><li>首先看本进程 JVM内部是否有符合要求的服务提供者。</li><li>JVM 内部没有，选择服务提供者 IP地址与本机 IP地址相同的本地合设的服务提供者进程，通过本地网卡回环调用服务提供则。</li><li>如果 VM内部没有，则发起远程调用。</li></ol><h1 id="4-路由规则"><a href="#4-路由规则" class="headerlink" title="4 路由规则"></a>4 路由规则</h1><h2 id="4-1-条件路由规则"><a href="#4-1-条件路由规则" class="headerlink" title="4.1 条件路由规则"></a>4.1 条件路由规则</h2><p>应用场景如下：</p><ol><li>通过 IP条件表达式进行黑白名单访问控制，例如 comsumerIP != 192.168.1.1</li><li>流量引导，只暴露部分服务提供者，防止整个集群服务都被冲垮，导致其它服务也不可用，例如 providerIP = 192.168.3*</li><li>读写分离：method=find<em>,list</em>,get<em>,query</em>=&gt;providerIP=192.168.1.*</li><li>前后台分离：app=web<em>=&gt;providerIP=192.168.1.</em>,app=java<em>=&gt;providerIP=192.168.2.</em></li><li>灰度升级，将 Web前台应用路由到新的服务版本上：app=web<em>=&gt;providerIP=192.168.1.</em></li></ol><h2 id="4-2-脚本路由规则"><a href="#4-2-脚本路由规则" class="headerlink" title="4.2 脚本路由规则"></a>4.2 脚本路由规则</h2><p>使用脚本来实现路由规则，在于动态编译，修改实时生效，常见的脚本语言有 JavaScript、Groovy、MVEL 等。</p><h1 id="5-路由策略定制"><a href="#5-路由策略定制" class="headerlink" title="5 路由策略定制"></a>5 路由策略定制</h1><p>除了提供默认的路由策略之外，在架构上还需要支持业务扩展路由算法，实现业务自定义路由。  </p><ol><li>灰度升级，用户需要按照业务规则进行灰度路由：例如按照用户省份路由、按照请求来源中断类型（IOS、Android）、按照手机号段等；不同的用户按照规则路由到不同的集群环境中，例如没有同步升级的用户路由到升级前的环境，同步配套升级的消费者请求路由到灰度升级后的新版本中。</li><li>服务故障、业务高峰期的导流：通过自定义路由，将异常的峰值流量导流到几台或者1 台服务器上，防止整个集群负载过重导致整个生产系统雪崩。</li></ol><p>路由扩展策略如下：  </p><ol><li>提供接口。</li><li>提供配置 XML Schema定义。</li><li>通过 Spring Bean 方式的服务发布、通过 JDK 的 SPI 方式扩展，即 META-INF/services。</li></ol><h1 id="6-配置化路由"><a href="#6-配置化路由" class="headerlink" title="6 配置化路由"></a>6 配置化路由</h1><ol><li>本地配置：包括服务提供者和服务消费者、默认全局配置三种。</li><li>统一注册管理：无论是服务提供者还是消费者，本地配置的路由策略统一注册到服务注册中心，进行集中化配置管理。</li><li>动态下发：运维人员通过服务治理 Portal修改路由规则，更新后的路由规则被持久化到服务注册中心。</li></ol><p>路由配置优先级：客户端配置&gt;服务端配置&gt;全局配置。</p><h1 id="7-最佳实践————多机房路由"><a href="#7-最佳实践————多机房路由" class="headerlink" title="7 最佳实践————多机房路由"></a>7 最佳实践————多机房路由</h1><p>为了能够相互发现对方的服务，不同机房会共用同一个服务注册中心集群（异地容灾机房除外）。假如机房1 发布了服务A，机房2 同样也发布了服务A，此时服务注册中心就会将2 个不同机房的服务A 地址信息推送给消费者，无论是机房1 还是机房2 的消费者，都将看到两个不同机房的服务。  </p><p>如果仅仅依靠随机、轮询等负载均衡策略，消息将会被路由到两个机房，达不到不跨机房调用的目标。此时可以使用配置条件路由策略，通过网段条件匹配来实现地址过滤。<br>也可以使用虚拟分组策略，将整个集群系统的服务提供者（跨机房）逻辑分成若干个组，某个消费者只访问一个虚拟分组的服务提供者，防止跨组服务调用。</p><h1 id="8-个人总结"><a href="#8-个人总结" class="headerlink" title="8 个人总结"></a>8 个人总结</h1><p>服务路由需要既具备丰富的路由策略，还要具备扩展能力，是非常重要的分布式下的基础功能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;分布式服务框架上线运行时都是集群组网，这意味着急群众存在某个服务的多实例部署，消费者如何从服务列表中选择合适的服务提供者进行调用，这就涉及到服务路由。&lt;/p&gt;
&lt;h1 id=&quot;1-透明化路由&quot;&gt;&lt;a href=&quot;#1-透明化路由&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>五、协议栈</title>
    <link href="http://www.liwenguang.cn/2018/05/27/distributed_principle_prictice/5.html/"/>
    <id>http://www.liwenguang.cn/2018/05/27/distributed_principle_prictice/5.html/</id>
    <published>2018-05-27T14:18:00.000Z</published>
    <updated>2018-05-28T16:08:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-关键技术点分析"><a href="#1-关键技术点分析" class="headerlink" title="1 关键技术点分析"></a>1 关键技术点分析</h1><h1 id="1-1-是否必须支持多协议"><a href="#1-1-是否必须支持多协议" class="headerlink" title="1.1 是否必须支持多协议"></a>1.1 是否必须支持多协议</h1><p>分布式服务框架需要具备通过扩展的方式支持多协议的能力，协议栈应该作为一个架构扩展点开放出来。</p><h1 id="1-2-公有协议还是私有协议"><a href="#1-2-公有协议还是私有协议" class="headerlink" title="1.2 公有协议还是私有协议"></a>1.2 公有协议还是私有协议</h1><p>以 Web Service 公有协议为例，它的性能存在如下缺陷：  </p><ol><li>SOAP 消息使用 XML 进行序列化，相比于 PB 等二进制序列化框架，性能低很多。</li><li>SOAP 通常由 HTTP 协议承载，HTTP 1.0 不支持双向全工通信，而且一般使用短连接通信，性能比较差。</li></ol><p>如果没有特殊需求，分布式服务框架默认使用性能更高、扩展性更好的私有协议（二进制）进行通信。对 HTTP/Restful 等公有协议进行扩展</p><h1 id="1-3-集成开元还是自研"><a href="#1-3-集成开元还是自研" class="headerlink" title="1.3 集成开元还是自研"></a>1.3 集成开元还是自研</h1><ol><li>如果已经有可以满足需求的框架，优先选择继承开源框架。</li><li>如果使用到的功能不多，或者对性能要求极高，可以考虑基于 Netty 自研。</li></ol><h1 id="2-功能设计"><a href="#2-功能设计" class="headerlink" title="2 功能设计"></a>2 功能设计</h1><h2 id="2-1-功能描述"><a href="#2-1-功能描述" class="headerlink" title="2.1 功能描述"></a>2.1 功能描述</h2><p>私有协议栈承载了业务内部各模块之间的消息交互和服务调用，主要功能如下：  </p><ol><li>定义了私有协议的通信模型和消息定义。</li><li>支持服务提供者和消费者之间采用点对点长连接通信</li><li>基于 Java NIO 通信框架，提供高性能的异步通信能力。</li><li>提供可扩展的编解码框架，支持多种序列化格式。</li><li>握手和安全认证机制。</li><li>链路的高可靠性。</li></ol><h2 id="2-2-通信模型"><a href="#2-2-通信模型" class="headerlink" title="2.2 通信模型"></a>2.2 通信模型</h2><p>私有协议栈通信模型如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/5_1.png" alt="">  </p><ol><li>客户端发送握手请求消息，携带节点ID 等有效神风认证信息。</li><li>服务端对握手请求消息进行合法性校验，包括节点ID 有效性校验、节点重复登录校验和IP 地址合法性校验，校验通过后，返回登录成功的握手应答消息。</li><li>链路建立成功之后，客户端发送业务消息。</li><li>链路成功之后，服务端发送心跳消息。</li><li>链路建立成功之后，客户端发送心跳消息。</li><li>链路建立成功之后，服务端发送业务消息。</li><li>服务端退出时，服务端关闭连接，客户端感知对方关闭连接后，被动关闭客户端连接。</li></ol><h2 id="2-3-协议消息定义"><a href="#2-3-协议消息定义" class="headerlink" title="2.3 协议消息定义"></a>2.3 协议消息定义</h2><p>通信协议栈的消息模型分为两部分，消息头和消息体。消息头存放协议公共字段和用户扩展字段，消息体则用于承载消息内容。以 HTTP 协议为例，请求消息头允许客户端向服务端传递请求的附加信息以及客户端自身的信息，常见的消息头关键字有 Accept、Authorization、Host 等。</p><h2 id="2-4-协议消息的序列化和反序列化"><a href="#2-4-协议消息的序列化和反序列化" class="headerlink" title="2.4 协议消息的序列化和反序列化"></a>2.4 协议消息的序列化和反序列化</h2><p>消息的序列化分为两部分，消息头的序列化和消息体的序列化，两者采用的机制不一样。原因是协议栈可以由不同的序列化框架承载，标识序列化格式的字段在消息头中定义，因此我们必须首先对消息头做通用解码，获取序列化格式，然后根据类型再调用对应的解码器对消息体做解码。消息头是通用编解码。</p><h2 id="2-5-链路创建"><a href="#2-5-链路创建" class="headerlink" title="2.5 链路创建"></a>2.5 链路创建</h2><p>协议栈包括服务端和客户端，对于上层应用来说，一个节点可能既是服务端也是客户端。<br>考虑到安全，链路简历需要通过基于 IP 地址或者号段的黑白名单安全认证机制，以及通过秘钥等。</p><h2 id="2-6-链路关闭"><a href="#2-6-链路关闭" class="headerlink" title="2.6 链路关闭"></a>2.6 链路关闭</h2><p>由于采用长连接通信，在正常的业务运行期间，双方通过心跳和业务消息维持链路，任何一方都不需要主动关闭连接。以下情况，客户端和服务端需要关闭连接：  </p><ol><li>当对方宕机或重启时，会主动关闭链路。</li><li>消息读写过程中，发生了 I/O 异常，需要主动关闭连接。</li><li>心跳消息读写过程中发生了 I/O 异常，需要主动关闭连接。</li><li>心跳超时，需要主动关闭连接。</li><li>发生编码异常或其它不可恢复错误时，需要主动关闭连接。</li></ol><h1 id="3-可靠性分析"><a href="#3-可靠性分析" class="headerlink" title="3 可靠性分析"></a>3 可靠性分析</h1><h2 id="3-1-客户端连接超时"><a href="#3-1-客户端连接超时" class="headerlink" title="3.1 客户端连接超时"></a>3.1 客户端连接超时</h2><p>客户端业务需要、以及资源的长时间占有等，需要设置超时时间。</p><h2 id="3-2-客户端重连机制"><a href="#3-2-客户端重连机制" class="headerlink" title="3.2 客户端重连机制"></a>3.2 客户端重连机制</h2><p>客户端通过链路关闭监听器监听链路状态，如果链路中断，等待 INTERVAL 时间后，由客户端发起重连操作，如果重连失败，间隔周期 INTERVAL 后再次发起重连，直到重连成功。  </p><p>为了保证服务端能够有充足的时间释放句柄资源，在首次断连时客户端需要等待 INTERVAL 时间之后再发起重连，而不是失败后就立即重连。</p><h2 id="3-3-客户端重复握手保护"><a href="#3-3-客户端重复握手保护" class="headerlink" title="3.3 客户端重复握手保护"></a>3.3 客户端重复握手保护</h2><p>当客户端握手成功之后，在链路处于正常状态下，不允许客户端重复握手，以防止客户端在异常状态下反复重连导致句柄资源被耗尽。  </p><p>服务端接收到客户端的握手请求消息之后，首先对IP 地址进行合法性检验，如果校验成功，在缓存的地址表中查看客户端是否已经登录，如果已经登录，则拒绝登录，返回错误码 -1，同时关闭 TCP 链路，并在服务端的日志中打印握手失败的原因。  </p><p>客户端接收到握手失败的应答消息之后，关闭客户端的 TCP连接，等待 INTERVAL 时间之后，再次发起 TCP连接，直到认证成功。</p><h2 id="3-4-消息缓存重发"><a href="#3-4-消息缓存重发" class="headerlink" title="3.4 消息缓存重发"></a>3.4 消息缓存重发</h2><p>无论客户端还是服务端，当发生链路中断之后，在链路恢复之前，缓存在消息队列中待发送的消息不能丢失，等链路恢复之后，重新发送这些消息，保证链路中断期间消息不丢失。  </p><p>考虑到内存溢出的风险，建议消息缓存队列设置上限，当达到上限之后，应该拒绝继续向该队列添加新的消息。</p><h2 id="3-5-心跳机制"><a href="#3-5-心跳机制" class="headerlink" title="3.5 心跳机制"></a>3.5 心跳机制</h2><p>在凌晨等业务低谷期时段，如果发生网络闪断、连接被 Hang 住等网络问题时，由于没有业务消息，应用金城很难发现。到了白天业务高峰期时，会发生大量的网络通信失败。为了解决这个问题，在网络空闲时采用心跳机制来检测链路的互通性，一旦发现网络网络故障，立即关闭链路，主动重连。</p><h1 id="4-最佳实现–协议的前后兼容性"><a href="#4-最佳实现–协议的前后兼容性" class="headerlink" title="4 最佳实现–协议的前后兼容性"></a>4 最佳实现–协议的前后兼容性</h1><p>考虑到协议的前向兼容性，核心的设计原则有2 个：  </p><ol><li>消息头第一个字段中携带协议的版本号，用于标识消息协议版本。</li><li>消息头最后一个字段是 Map 类型的扩展字段，用于服务框架自身或者用户扩展消息头。</li></ol><h1 id="5-个人总结"><a href="#5-个人总结" class="headerlink" title="5 个人总结"></a>5 个人总结</h1><p>协议栈描述了分布式服务框架的通信契约，序列化和反序列化框架用于协议消息对象和二进制数组之间的相互转换，通信框架在技术上承载协议，协议依赖通信。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-关键技术点分析&quot;&gt;&lt;a href=&quot;#1-关键技术点分析&quot; class=&quot;headerlink&quot; title=&quot;1 关键技术点分析&quot;&gt;&lt;/a&gt;1 关键技术点分析&lt;/h1&gt;&lt;h1 id=&quot;1-1-是否必须支持多协议&quot;&gt;&lt;a href=&quot;#1-1-是否必须支持多协
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>四、序列化和反序列化</title>
    <link href="http://www.liwenguang.cn/2018/05/22/distributed_principle_prictice/4.html/"/>
    <id>http://www.liwenguang.cn/2018/05/22/distributed_principle_prictice/4.html/</id>
    <published>2018-05-22T14:41:00.000Z</published>
    <updated>2018-05-26T15:36:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-几个关键概念澄清"><a href="#1-几个关键概念澄清" class="headerlink" title="1 几个关键概念澄清"></a>1 几个关键概念澄清</h1><p>通常我们习惯将序列化（Serialization）称为编码（Encode）,它将对象序列化为字节数组，用于网络传输、数据持久化或其它用途。<br>反之，反序列化（Deserialization）/解码（Decode）把从网络、磁盘等读取的字节数组还原成原始对象（通常是原始对象的副本）。</p><h2 id="1-1-序列化与通信框架的关系"><a href="#1-1-序列化与通信框架的关系" class="headerlink" title="1.1 序列化与通信框架的关系"></a>1.1 序列化与通信框架的关系</h2><p>序列化与通信框架不是强耦合的关系，通信框架提供的编解码框架可以非常方便地支持用户通过扩展实现自定义的序列化格式。通信框架的编解码接口作为可选插件，并不强制用户一定要在通信框架内部实现消息的序列化和反序列化。</p><h2 id="1-2-序列化与通信协议的关系"><a href="#1-2-序列化与通信协议的关系" class="headerlink" title="1.2 序列化与通信协议的关系"></a>1.2 序列化与通信协议的关系</h2><p>序列化与通信协议是解耦的，同一种通信协议可能由多种序列化方式承载，同一种序列化方式也可以用在不同协议里。  </p><p>以 HTTP 协议为例，承载消息体的可以是 XML、JSON 等文本类的协议，也可以是图片附件等二进制流媒体协议。<br>在设计分布式服务框架时，序列化和反序列化是一个独立的接口和插件，它可以被多种协议重用、替换和扩展，以实现服务框架序列化方式的多样性。</p><h2 id="1-3-是否需要支持多种序列化方式"><a href="#1-3-是否需要支持多种序列化方式" class="headerlink" title="1.3 是否需要支持多种序列化方式"></a>1.3 是否需要支持多种序列化方式</h2><p>整体而言，序列化可以分为文本类和二进制类两种，不同的业务场景需求也不同，分布式服务框架面向的领域是多样化的，因此它的序列化/反序列化框架需要具备如下特性：  </p><ol><li>默认支持多种常用的序列化/反序列化方式，文本类例如 XML/JSON 等，二进制的如 PB（Protocol Buffer）/Thrift 等。</li><li>序列化框架可扩展，用户可以非常灵活、方便地扩展其它序列化方式。</li></ol><h1 id="2-功能设计"><a href="#2-功能设计" class="headerlink" title="2 功能设计"></a>2 功能设计</h1><p>从功能、跨语言支持、兼容性、性能等多个角度进行综合考量。  </p><ol><li>功能丰富。</li><li>跨语言支持。</li><li>兼容性</li><li>性能。</li></ol><h1 id="3-扩展性设计"><a href="#3-扩展性设计" class="headerlink" title="3 扩展性设计"></a>3 扩展性设计</h1><p>利用 Netty 提供的编解码框架，可以非常快速的实现序列化/反序列化框架的扩展。</p><h2 id="3-1-内置的序列化-反序列化功能类"><a href="#3-1-内置的序列化-反序列化功能类" class="headerlink" title="3.1 内置的序列化/反序列化功能类"></a>3.1 内置的序列化/反序列化功能类</h2><p>为了降低用户的开发难度，Netty 对常用的功能和 API 做了装饰，以屏蔽底层的实现细节。Netty 内置的编解码功能包括 base64、Protobuf、JBoss Marshalling、spdy 等。</p><h2 id="3-2-反序列化扩展"><a href="#3-2-反序列化扩展" class="headerlink" title="3.2 反序列化扩展"></a>3.2 反序列化扩展</h2><ol><li>业务发布服务的时候，可以指定协议类型和承载数据的序列化方式，例如将购买商品服务发布成 HTTP 服务，序列化格式采用 XML；同时允许用户指定新增的序列化格式发布服务。</li><li>序列化类库能够以插件的格式插入到通信调用链中，实现序列化格式的扩展。在这个过程中，需要考虑 TCP 的黏包和拆包等底层相关的技术细节。</li></ol><p>我们看半包的处理，如果不处理半包，Netty 调用 decode 方法传递的 ByteBuf 对象可能就是个半包，我们拿半包做反序列化就会失败，因此在反序列化之前，我们需要保证调用解码方法时传递的是个完整的数据包。  </p><p>了解 TCP 通信机制的渎职应该都知道 TCP 底层的黏包和拆包，当我们在接收消息的时候，不能认为读取到的报文就是个整包消息，特别是对于采用非阻塞 I/O 和长连接通信的程序。<br>如何区分一个整包消息，通常有如下四种做法：  </p><ol><li>固定长度，例如每 120 个字节代表一个整包消息，不足的前面补位。解码器在处理这类定长消息的时候比较简单，每次读到指定长度的字节后进行解码。</li><li>通过回车换行符区分消息，例如 HTTP 协议。这类区分消息的方式多用于文本协议。</li><li>通过特定的分隔符区分整包消息。</li><li>通过在协议头/消息头中设置长度字段来标识整包消息。</li></ol><h1 id="4-最佳实践"><a href="#4-最佳实践" class="headerlink" title="4 最佳实践"></a>4 最佳实践</h1><h2 id="4-1-接口的前向兼容性规范"><a href="#4-1-接口的前向兼容性规范" class="headerlink" title="4.1 接口的前向兼容性规范"></a>4.1 接口的前向兼容性规范</h2><ol><li>制定”分布式服务框架接口兼容性规范“，在规范中要明确服务框架支持哪些兼容性，例如新增字段、删除字段还是修改字段。</li><li>引导客户。</li></ol><h2 id="4-2-高并发下的稳定性"><a href="#4-2-高并发下的稳定性" class="headerlink" title="4.2 高并发下的稳定性"></a>4.2 高并发下的稳定性</h2><p>需要模拟现网高并发场景对序列化框架做压测和稳定性测试，如果序列化框架存在全局锁较激烈的线程竞争等问题，多线程、高并发压力测试就会出现问题。究其原因是因为一些序列化框架为了实现线程安全，使用了全局锁等，这从实用角度看确实简单，但是在高并发场景下就会出现性能下降、耗时不稳定等问题。  </p><p>解决此类问题的方案很多，例如每个线程聚合一个序列化/反序列化类库，避免多线程竞争。</p><h1 id="5-个人总结"><a href="#5-个人总结" class="headerlink" title="5 个人总结"></a>5 个人总结</h1><p>序列化/反序列化是 RPC 框架的基础组成部分，从性能、业务考虑，而 Netty 非常适合去做扩展。当然，还是清楚其中的经典黏包、拆包。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-几个关键概念澄清&quot;&gt;&lt;a href=&quot;#1-几个关键概念澄清&quot; class=&quot;headerlink&quot; title=&quot;1 几个关键概念澄清&quot;&gt;&lt;/a&gt;1 几个关键概念澄清&lt;/h1&gt;&lt;p&gt;通常我们习惯将序列化（Serialization）称为编码（Encode）,
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>三、通信框架</title>
    <link href="http://www.liwenguang.cn/2018/05/20/distributed_principle_prictice/3.html/"/>
    <id>http://www.liwenguang.cn/2018/05/20/distributed_principle_prictice/3.html/</id>
    <published>2018-05-20T14:55:00.000Z</published>
    <updated>2018-05-22T14:41:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="恭喜-RNG，恭喜-UZI"><a href="#恭喜-RNG，恭喜-UZI" class="headerlink" title="恭喜 RNG，恭喜 UZI"></a>恭喜 RNG，恭喜 UZI</h1><p>六年<br>恋恋不忘<br>必有回响<img src="http://photocdn.sohu.com/20180521/Img538252610.jpg" alt=""></p><hr><h1 id="1-关键技术点分析"><a href="#1-关键技术点分析" class="headerlink" title="1 关键技术点分析"></a>1 关键技术点分析</h1><h2 id="1-1-长连接还是短连接"><a href="#1-1-长连接还是短连接" class="headerlink" title="1.1 长连接还是短连接"></a>1.1 长连接还是短连接</h2><p>绝大多数的分布式服务框架（RPC框架）都推荐使用长连接进行内部通信，为什么选择长连接而不是短连接呢？具体原因如下：  </p><ol><li>相对比短连接，长连接更节省资源。长连接只会在首次创建时或者链路断连重连才创建链路，链路创建成功之后服务提供者和消费者会通过业务消息和心跳维系链路，实现多消息复用同一个链路节省资源。</li><li>远程通信是常态，调用时延是关键指标：服务化之后，本地 API 调用变成了远程服务调用，大量本地方法演进成了跨进程通信，网络时延称为关键指标之一。相比于一次简单的服务调用，链路的重建通常耗时更多，这就会导致链路层的时延消耗远远大于服务调用本身的损耗，这对于大型的业务系统而言是无法接受的。</li></ol><h2 id="1-2-BIO-还是-NIO"><a href="#1-2-BIO-还是-NIO" class="headerlink" title="1.2 BIO 还是 NIO"></a>1.2 BIO 还是 NIO</h2><p>经典的 BIO 通信模型如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/3_1.png" alt=""><br>采用 BIO 通信模型的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接，它接收到客户端连接请求后为每个客户端创建一个新的线程进行链路处理，处理完成后，通过输出流返回给客户端，线程销毁，这就是典型的一请求一应答通信模型。<br>该模型最大的问题就是缺乏弹性伸缩能力，当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数呈 1:1 的正比关系。由于线程是 Java 虚拟机非常宝贵的系统资源，当线程数膨胀之后，系统的性能将急剧下降，随着并发访问量的继续增大，系统会发生线程堆栈溢出、创建新线程失败等问题，并最终导致进程宕机或者僵死，不能对外提供服务。  </p><p>在 I/O 编程过程中，当需要同时处理多个客户端接入请求时，可以利用多线程或 I/O 多路复用技术进行处理。 I/O 多路复用技术通过把多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型相比，I/O 多路复用的最大优势是系统开销小，系统不需要创建新的额外线程/进程，也不需要维护这些线程/进程的运行，节省系统资源。  </p><p>JDK1.4 提供了对非阻塞I/O（NIO）的支持，JDK1.5 使用 epoll 替代了传统的 select/poll，极大提升了 NIO 通信的性能。<br>NIO 采用多路复用技术，一个多路复用器 Selector 可以同时轮询多个 Channel ，由于 JDK 使用了 epoll() 代替了传统的 select 实现，所以它并没有最大连接句柄 1024/2048 的限制。这就意味着只需要一个线程负责 Selector 的轮询，就可以接入成千上万的客户端。<br>采用多路复用器 Selector 实现的 Reactor 通信模型如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/3_2.png" alt=""></p><h2 id="1-3-自研还是选择开源-NIO-框架"><a href="#1-3-自研还是选择开源-NIO-框架" class="headerlink" title="1.3 自研还是选择开源 NIO 框架"></a>1.3 自研还是选择开源 NIO 框架</h2><p>选择 Netty！</p><h1 id="2-功能设计"><a href="#2-功能设计" class="headerlink" title="2 功能设计"></a>2 功能设计</h1><p>分布式服务框架的底层通信框架首先是一个通用的通信框架，它不应该与具体的协议绑定。基于通信框架智商，可以构建私有协议栈和公有协议栈。<br>架构原理如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/3_3.png" alt=""></p><h2 id="2-1-服务端设计"><a href="#2-1-服务端设计" class="headerlink" title="2.1 服务端设计"></a>2.1 服务端设计</h2><p>通信框架服务端的职责如下：  </p><ol><li>提供上层 API，用于初始化服务端实例，设置服务端通信相关参数，包括服务端的 I/O 线程池、监听地址、TCP 相关参数、接收和发送缓冲区大小等。</li><li>提供可扩展的编解码插件，用户可以通过扩展的方式实现自定义协议的编码和解码。</li><li>提供拦截面，用于私有协议栈开发。例如通过新增鉴权插件实现服务端对客户端的安全认证。</li></ol><h2 id="2-2-客户端设计"><a href="#2-2-客户端设计" class="headerlink" title="2.2 客户端设计"></a>2.2 客户端设计</h2><p>客户端需要考虑网络连接超时、连接失败等异常场景。</p><h1 id="3-可靠性设计"><a href="#3-可靠性设计" class="headerlink" title="3 可靠性设计"></a>3 可靠性设计</h1><h2 id="3-1-链路有效性检测"><a href="#3-1-链路有效性检测" class="headerlink" title="3.1 链路有效性检测"></a>3.1 链路有效性检测</h2><p>当网络发生单通、连接被防火墙 Hang 住，长时间 GC 或者通信线程发生非预期异常时，会导致链路不可用且不易被及时发现。特别是异常发生在凌晨业务低谷期间，当早晨业务高峰期到来时，由于链路不可用会导致瞬间的大批量业务失败或者超时。  </p><p>从技术层面看，要解决链路的可靠性问题，必须周期性地对链路进行有效性检测。目前最流行和最通用的做法就是心跳检测。  </p><ol><li>TCP 层面的心跳检测，即 TCP 的 Keep-Alive 机制，它的作用域是整个 TCP 协议栈。</li><li>协议层的心跳检测，主要存在于长连接协议中，例如 SMPP 协议。</li><li>应用层的心跳检测，主要由各业务产品通过约定方式定时给对方发送心跳消息实现。</li></ol><p>心跳的检测原理如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/3_8.png" alt=""></p><p>不同的协议，心跳检测机制也存在差异，归类两类：  </p><ol><li>Ping-Pong 型心跳：由通信一方定时发送 Ping 消息，对方接收到 Ping 消息之后，立即返回 Pong 应答消息给对方，属于请求-响应型心跳。</li><li>Ping-Ping 型心跳：不区分心跳请求和应答，由通信双方按照约定定时向对方发送心跳 Ping 消息，属于双向心跳。</li></ol><p>心跳检测策略如下：  </p><ol><li>连续 N 次心跳检测都没有收到对方的 Pong 应答消息或者 Ping 请求消息，则认为链路已经发生逻辑失效，这被称为心跳超时。</li><li>读取和发送心跳消息的时候如果直接发生了 I/O 异常，说明链路已经失效，这被称为心跳失败。</li></ol><p>无论发生心跳超时还是心跳失败，都需要关闭链路，由客户端发起重连操作，保证链路能够恢复正常。<br>Netty 的心跳检测实际上是利用了链路空闲检测机制实现的，它的空闲检测机制分为三种：  </p><ul><li>读空闲，链路持续时间 t 没有读取到任何消息。</li><li>写空闲，链路持续时间 t 没有发送任何消息。</li><li>读写空闲，链路持续时间 t 没有接受或者发送任何消息。</li></ul><h2 id="3-2-断连重连机制"><a href="#3-2-断连重连机制" class="headerlink" title="3.2 断连重连机制"></a>3.2 断连重连机制</h2><p>为了保证服务端能够有充足的时间释放句柄资源，在首次断连时客户端需要等待 INTERVAL 时间之后再发起重连，而不是失败后就立即重连。<br>为了保证句柄资源能够及时释放，无论什么场景下的重连失败，客户端都必须保证自身的资源被及时释放，包括但不限于 SocketChannel、Socket等。</p><h2 id="3-3-消息缓存重发"><a href="#3-3-消息缓存重发" class="headerlink" title="3.3 消息缓存重发"></a>3.3 消息缓存重发</h2><p>当我们调用消息发送接口的时候，消息并没有真正被写入到 Socket 中，而是先放入 NIO 通信框架的消息发送队列中，由 Reactor 线程扫描待发送的消息队列，异步地发送给通信对端。假如很不辛，消息队列中积压了部分消息，此时链路中断，这会导致部分消息并没有真正发送给通信对端，如下图：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/3_9.png" alt="">  </p><p>发生此故障时，我们希望 NIO 框架能够自动实现消息缓存和重新发送，遗憾的是作为基础的 NIO 通信框架，无论是 Mina 还是 Netty，都没有提供该功能，需要通信框架自己封装实现。  </p><p>并非所有场景都需要通信框架做重发，例如服务框架的客户端，如果某个服务提供者不可用，会自动切换到下一个可用的服务提供者之上。假定是链路中断导致的服务提供者不可用，即便链路重新恢复，也没有必要将之前积压的消息重新发送，因为消息已经通过 FailOver 机制切换到另一个服务提供者处理。所以，消息缓存重发只是一种策略，通信框架应该支持链路级重发策略。</p><h2 id="3-4-资源优雅释放"><a href="#3-4-资源优雅释放" class="headerlink" title="3.4 资源优雅释放"></a>3.4 资源优雅释放</h2><p>Java 的优雅停机通常通过注册 JDK 的 ShutdownHook 来实现，当系统接收到退出指令后，首先标记系统处于退出状态，不再接收新的消息，然后将积压的消息处理完，最后调用资源回收接口将资源销毁，最后各线程退出执行。  </p><p>通常优雅退出有个时间限制，例如 30s，如果到达执行时间仍然没有完成推出前的操作，则由监控监本直接 kill -9 pid，强制退出。</p><h1 id="4-性能设计"><a href="#4-性能设计" class="headerlink" title="4 性能设计"></a>4 性能设计</h1><p>分布式服务框架被广泛应用于大数据处理、互联网消息中间件、游戏和金融行业等。对通信框架有很高的性能要求。</p><h2 id="4-1-性能差的三宗罪"><a href="#4-1-性能差的三宗罪" class="headerlink" title="4.1 性能差的三宗罪"></a>4.1 性能差的三宗罪</h2><ol><li>网络传输方式：同步阻塞 I/O，采用 BIO 通信模型的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接，接收到客户端连接之后，为其创建一个新的线程处理请求消息，处理完成之后，返回应答消息给客户端，线程销毁，这就是典型的一请求一应答模型。该架构最大的问题就是不具备弹性伸缩能力，当并发访问量增加后，服务端的线程个数和并发访问数成线性正比，导致并发量的增加，发生句柄溢出。</li><li>序列化性能差：Java 序列化机制是 Java 内部的一种对象编解码技术，无法跨语言；相对其它开源的序列化框架，Java 序列化后的码流太大，导致额外的资源占用；序列化性能差，资源占用率高（主要是 CPU 资源占用高）。</li><li>线程模型问题：由于采用同步阻塞 I/O，导致每个 TCP 连接都占用了一个线程。</li></ol><h2 id="4-2-通信性能三原则"><a href="#4-2-通信性能三原则" class="headerlink" title="4.2 通信性能三原则"></a>4.2 通信性能三原则</h2><ol><li>传输：用什么样的通道将数据发送给对方：BIO/NIO/AIO。I/O 模型在很大程度上决定了通信的性能。</li><li>协议：采用什么样的通信协议， HTTP 等公有协议或者内部私有协议。通常内部私有协议可以被设计得更优。</li><li>线程：数据报如何读取？读取之后的编解码在哪个线程进行？编解码后的消息如何派发？Reactor 线程模型的不同，对性能的影响也非常大。</li></ol><h2 id="4-3-高性能之道"><a href="#4-3-高性能之道" class="headerlink" title="4.3 高性能之道"></a>4.3 高性能之道</h2><p>Netty 支持高性能通信的架构特性进行总结：  </p><ol><li>异步非阻塞通信：Netty 的 I/O 线程 NioEventLoop 由于聚合了多路复用器 Selector，可以同时并发处理成百上千个客户端 SocketChannel。由于读写都是非阻塞的，这就可以充分提升 I/O 的运行效率，避免由频繁的 I/O 阻塞导致的线程挂起。另外，由于 Netty 采用了异步通信模式，一个 I/O 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 I/O 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。</li><li>高效的 I/O 线程模型：Netty 支持 Reactor 单线程模型、Reactor 多线程模型和主从 Reactor 多线程模型，可以满足不同的容量和性能需求。</li><li>高性能的序列化框架：默认提供了 Protobuf 二进制序列化框架，其它二进制序列化框架可以进行编解码框架扩展实现。  </li></ol><p>还支持零拷贝、内存池等其它性能相关的特性。</p><h1 id="5-最佳实践"><a href="#5-最佳实践" class="headerlink" title="5 最佳实践"></a>5 最佳实践</h1><ol><li>服务端只负责客户端的接入，不处理 I/O 读写操作，因此服务端的 boosGroup 设置线程数为1：<code>EventLoopGroup bossGroup = new NioEventLoopGroup(1);</code>。</li><li>客户端的 NioEventLoopGroup 由于服务提供者可能有 1000个或更多，导致创建了 1000个对象，可以使用大的线程池，或者创建一个包含 NioEventLoopGroup 的数组，将客户端连接按照 Hash 算法分组，将所有连接均匀的打散在 NioEventLoopGroup 中。</li></ol><h1 id="6-个人总结"><a href="#6-个人总结" class="headerlink" title="6 个人总结"></a>6 个人总结</h1><p>通信框架的重点在于 BIO、NIO、AIO，以及序列化。<br>这就是为什么别人面试会问 BIO/NIO/AIO/序列化。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;恭喜-RNG，恭喜-UZI&quot;&gt;&lt;a href=&quot;#恭喜-RNG，恭喜-UZI&quot; class=&quot;headerlink&quot; title=&quot;恭喜 RNG，恭喜 UZI&quot;&gt;&lt;/a&gt;恭喜 RNG，恭喜 UZI&lt;/h1&gt;&lt;p&gt;六年&lt;br&gt;恋恋不忘&lt;br&gt;必有回响
&lt;img s
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>二、分布式服务框架入门</title>
    <link href="http://www.liwenguang.cn/2018/05/19/distributed_principle_prictice/2.html/"/>
    <id>http://www.liwenguang.cn/2018/05/19/distributed_principle_prictice/2.html/</id>
    <published>2018-05-19T09:00:00.000Z</published>
    <updated>2018-05-12T10:15:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-分布式服务框架诞生背景"><a href="#1-分布式服务框架诞生背景" class="headerlink" title="1 分布式服务框架诞生背景"></a>1 分布式服务框架诞生背景</h1><h2 id="1-1-集中式到分布式"><a href="#1-1-集中式到分布式" class="headerlink" title="1.1 集中式到分布式"></a>1.1 集中式到分布式</h2><p><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_1.png" alt="">  </p><ol><li>业务发展、应用规模变大，大型复杂应用的开发维护成本高，部署效率低，应用数量膨胀，数据库连接数变高。</li><li>代码复用低：由于公共模块都是进程内部的本地 API 调用，开发者按需开发，导致大量相同功能的 API 被重复开发。一旦涉及到公共模块的功能变更，所有重复实现都需要重新修改、编译和测试。</li><li>敏捷持续交付：想要在一个架构师都无法理解的巨无霸业务中新增或者修改一个功能，难度是非常大的。业务模块之间的循环依赖、重复 API 定义和开发、不合理的调用、冗长复杂的业务流程对新特性的上线简直是梦魇。  </li></ol><p>大规模系统架构的设计一般就是尽可能的拆分，以达到更好的独立扩展、部署、开发效率等。<br>具体的拆分策略大体上可以分为横向拆分和纵向拆分。  </p><p>纵向拆分：不同业务模块独立部署，例如一个 CRM 系统就可以根据客户域、产品域、资源域、营销管理域等拆分。由大变小、分而治之。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_2.png" alt="">  </p><p>横向拆分：将核心的、公共的业务拆分出来，通过分布式服务框架对业务进行服务化，消费者通过标准的契约来消费这些服务。服务提供者独立打包、部署，与消费者解耦。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_3.png" alt=""></p><h2 id="1-2-引入服务治理"><a href="#1-2-引入服务治理" class="headerlink" title="1.2 引入服务治理"></a>1.2 引入服务治理</h2><p>使用 RPC 框架对业务进行拆分之后，随着服务数的增多，急需一个服务治理框架，有效管控服务，提升服务运行期质量，防止业务服务代码架构腐化。因为，服务治理的主要应用如下：  </p><ol><li>生命周期管理：服务上线下线通知机制规范化。</li><li>服务容量规划。</li><li>运行期治理：对非核心服务采取降级、限流措施；缓存失效时，系统压力转移到数据库，服务调用时延突然增大，业务失败率升高，需要在线调大服务调用超时时间，保证业务成功率。</li><li>服务安全。  </li></ol><p>典型的 SOA 服务治理生命周期如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_4.png" alt=""></p><ol><li>计划：确定服务治理的重点。</li><li>定义：定义服务治理模型。</li><li>启用：实现并实施服务治理。</li><li>度量：根据实施效果，改进服务治理模型。</li></ol><h1 id="2-业务分布式服务框架介绍"><a href="#2-业务分布式服务框架介绍" class="headerlink" title="2 业务分布式服务框架介绍"></a>2 业务分布式服务框架介绍</h1><h2 id="2-1-阿里-Dubbo"><a href="#2-1-阿里-Dubbo" class="headerlink" title="2.1 阿里 Dubbo"></a>2.1 阿里 Dubbo</h2><p>架构图如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_5.png" alt=""><br>功能总结：  </p><ol><li>根据服务提供者配置的 XML 文件将服务按照指定协议发布，完成服务的初始化工作。</li><li>服务提供者根据配置的服务注册中心地址连接服务注册中心，将服务提供者信息发布到服务注册中心。</li><li>消费者根据服务消费者 XML 配置文件的服务引用信息，连接注册中心，获取指定服务的地址等路由信息。</li><li>服务注册中心根据服务订阅关系，动态地向指定消费者推送服务地址信息。</li><li>消费者调用远程服务时，根据路由策略，从本地缓存的服务提供者地址列表中选择一个服务提供者，然后根据协议类型建立链路，跨进程调用服务提供者。  </li></ol><p>原理图如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_6.png" alt=""></p><h2 id="2-2-淘宝-HSF"><a href="#2-2-淘宝-HSF" class="headerlink" title="2.2 淘宝 HSF"></a>2.2 淘宝 HSF</h2><p>架构图如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_7.png" alt=""><br>功能总结：  </p><ol><li>配置 XML 方式发布和消费服务。</li><li>插件管理体系：平台与应用分开部署，运行期依赖，外部采用与应用独立的 classloader 隔离，内部采用 OSGI 隔离。</li><li>异步 NIO 通信。多种序列化方式。服务提供者和消费者之间采用长连接通信。</li><li>灵活的路由能力：客户端软负载，随机、轮询等多种路由策略，支持容灾和失效恢复等。</li><li>多协议支持：WebService、PB（Protocol buffer）和 Hession（HTTP）等。</li></ol><p>整体结构图如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_8.png" alt=""></p><h2 id="2-3-亚马逊-Coral-Service"><a href="#2-3-亚马逊-Coral-Service" class="headerlink" title="2.3 亚马逊 Coral Service"></a>2.3 亚马逊 Coral Service</h2><h1 id="3-分布式服务框架设计"><a href="#3-分布式服务框架设计" class="headerlink" title="3 分布式服务框架设计"></a>3 分布式服务框架设计</h1><p>本章介绍分布式服务框架的架构原理和概要设计。</p><h2 id="3-1-架构原理"><a href="#3-1-架构原理" class="headerlink" title="3.1 架构原理"></a>3.1 架构原理</h2><p><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/2_10.png" alt=""><br>通常分布式服务框架的架构可以抽象为三层：  </p><ol><li>RPC 层：包括底层通信框架（例如 NIO 框架的封装、公有协议的封装等）、序列化和反序列化框架、用于屏蔽底层通信协议细节和序列化方式差异的 Remoting 框架。</li><li>Filter Chain 层：服务调用职责链，提供多种服务调用切面供框架自身和使用者扩展，例如负责均衡、服务调用性能统计、服务调用完成通知机制、失败重发等。</li><li>Service 层：主要包括 Java 动态代理，消费者使用，主要用于将服务提供者的接口封装成远程服务调用：Java 反射，服务提供者使用，根据消费者请求消息中的接口名、方法名、参数列表反射调用服务提供者的接口本地实现类。</li></ol><p>从功能角度看，分布式服务框架通常会包含另外两个重要功能：服务治理中心和服务注册中心。</p><h2 id="3-2-功能特性"><a href="#3-2-功能特性" class="headerlink" title="3.2 功能特性"></a>3.2 功能特性</h2><ol><li>服务订阅发布之配置化发布和引用服务：支持通过 XML 配置的方式发布和导入服务，降低对业务代码的侵入。</li><li>服务订阅发布之服务自动发现机制：由注册中心推送服务地址，消费者不需要配置服务提供者地址，服务地址透明化。</li><li>服务订阅发布之服务在线注册和去注册：支持运行态注册新服务，也支持运行态取消某个服务的注册。</li><li>服务路由之默认提供随机路由、轮询、基于权重的路由策略等。</li><li>服务路由之粘滞连接：总是向同一个提供方发起请求，除非此提供方挂掉，再切换到另一台。</li><li>服务路由之路由定制：支持用户自定义路由策略。</li><li>集群容错之 FailOver：失败自动切换，常用读操作；也可用于幂等性写操作。</li><li>集群容错之 Failback：失败自动恢复，后台记录失败请求，定时重发，通常用于消息通知操作。</li><li>集群容错之 Failfast：快速失败，只发起一次调用，失败立即报错，通常用于非幂等性的写操作。</li><li>服务调用之同步调用：消费者发起服务调用之后，同步阻塞等待服务端响应。</li><li>服务调用之异步调用：消费者发起服务调用之后，不阻塞立即返回，由服务端返回应答后异步通知消费者。</li><li>服务调用之并行调用：消费者同时对多个服务提供者批量发起服务调用请求，批量发起请求，集中等待应答。</li><li>多协议之私有协议：支持二进制等私有协议，支持自定义。</li><li>多协议之公有协议：支持 Web Service 等公有协议，用于外部服务对象。</li><li>序列化方式之二进制类序列化：支持 Thrift、Protocol buffer 等二进制协议，提升序列化性能。</li><li>序列化方式之文本类序列化：支持 JSON、XML 等文本类型的序列化方式。</li><li>统一配置之本地静态配置：安装部署一次，运行态不修改的配置，可以存放到本地配置文件中。</li><li>统一配置之基于配置中心的动态配置：运行态需要调整的参数，统一放到配置中心，修改之后统一下发，实时生效。</li></ol><h2 id="3-3-服务治理"><a href="#3-3-服务治理" class="headerlink" title="3.3 服务治理"></a>3.3 服务治理</h2><ol><li>服务运行态管控之服务路由：业务高峰期，通过动态修改路由策略实现导流。</li><li>服务运行态管控之服务限流：资源成为瓶颈时，服务端和消费者的动态流控。</li><li>服务运行态管控之服务迁入迁出：实现资源的动态分配。</li><li>服务运行态管控之服务降级：服务提供者故障时或者业务高峰期，进行服务强制或者容错降级，执行本地降级逻辑，保证系统平稳运行。</li><li>服务运行态管控之服务超时控制：动态调整超时时间，在业务高峰期保障业务调用成功率。</li><li>服务监控之性能统计：统计项包括服务调用时延、成功率、调用次数等。</li><li>服务监控之统计报表：提供多维度、实时和历史数据报表，同比、环比等性能对比数据，供运维、运营等使用。</li><li>服务监控之告警：指标异常，根据告警策略发送告警，包括但不限于短信、E-mail、记录日志等。</li><li>服务生命周期管理之上线审批：服务提供者不能随意线上发布服务，需要通过正规的审批流程批准之后才能上线。</li><li>服务生命周期管理之下线通知：服务提供者在下线某个服务之前一段时间，需要根据 SLA 策略，通知消费者。</li><li>服务生命周期管理之服务灰度发布：灰度环境划分原则、接口前向兼容性策略，以及消费者如何路由，都需要灰度发布引擎负责管理。</li><li>故障快速定界定位之分布式日志采集：支持在大规模分布式环境中实时采集容器、中间件和应用的各种日志。</li><li>故障快速定界定位之海量日志在线检索：支持分布式环境海量日志的在线检索，支持多维度索引和模糊查询。</li><li>故障快速定界定位之调用链可视化展示：通过分布式消息跟踪系统输出调用链，可视化、快速地进行故障定界。</li><li>故障快速定界定位之运行日志故障定位：通过调用链的故障关键字，在日志检索界面快速检索故障日志，用于故障的精确定位。</li><li>服务安全之敏感服务的授权策略：敏感服务如何授权，防止恶意调用。</li><li>服务安全之链路的安全防护“消费者和服务提供者之间的长连接，需要增加安全防护，例如基于 Token 的安全认证机制。</li></ol><h1 id="4-个人总结"><a href="#4-个人总结" class="headerlink" title="4 个人总结"></a>4 个人总结</h1><p>分布式服务框架在原理、目标是类似的，因此不同的分布式服务框架原理也是相似的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-分布式服务框架诞生背景&quot;&gt;&lt;a href=&quot;#1-分布式服务框架诞生背景&quot; class=&quot;headerlink&quot; title=&quot;1 分布式服务框架诞生背景&quot;&gt;&lt;/a&gt;1 分布式服务框架诞生背景&lt;/h1&gt;&lt;h2 id=&quot;1-1-集中式到分布式&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>一、应用框架演进</title>
    <link href="http://www.liwenguang.cn/2018/05/18/distributed_principle_prictice/1.html/"/>
    <id>http://www.liwenguang.cn/2018/05/18/distributed_principle_prictice/1.html/</id>
    <published>2018-05-18T15:41:00.000Z</published>
    <updated>2018-05-17T18:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-传统垂直应用架构"><a href="#1-传统垂直应用架构" class="headerlink" title="1 传统垂直应用架构"></a>1 传统垂直应用架构</h1><p>以经典的 MVC 垂直架构为例，通常分三层：  </p><ol><li>View：视图展示层，使用 JSP/JS/HTML+CSS。</li><li>Controller：调度控制层，请求的分发。</li><li>Model：应用模型层，业务数据和业务执行逻辑，被多个视图重用。</li></ol><p><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/1_1.png" alt=""></p><p>标准的 MVC 模式并不包含数据访问层，但实际开发中需要专门的数据库连接池和统一的数据库访问接口对接数据库，于是 ORM 框架逐渐流行起来。  </p><p>通常基于 MVC 架构开发的应用代码会统一打成一个 war 包，不同的应用功能之间通过本地 API 进行调用，基本不存在跨进程的远程服务调用。  </p><p>通常的基于热双机备份，判断应用进程宕机或僵死后，应用切换备机，然后尝试重新拉起主机。<br>而在高并发、大流量的应用场景中，需要做集群，通常前端通过 F5 等负载均衡器做七层负载均衡，后端做对等集群部署。<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/1_2.png" alt=""><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/1_3.png" alt=""></p><h1 id="2-RPC-架构"><a href="#2-RPC-架构" class="headerlink" title="2 RPC 架构"></a>2 RPC 架构</h1><p>RPC 全称 Remote Procedure Call，它是一种进程间通信方式。允许像调用本地服务一样调用远程服务，具体实现可以不同。</p><h2 id="2-1-RPC-框架原理"><a href="#2-1-RPC-框架原理" class="headerlink" title="2.1 RPC 框架原理"></a>2.1 RPC 框架原理</h2><p>RPC 框架的目标就是让远程过程（服务）调用更加简单、透明，RPC 框架负责屏蔽底层的传输方式（TCP/UDP）、序列化方式（XML/JSON/二进制）和通信细节。<br>调用原理图如下：<br><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/1_4.png" alt="">  </p><ol><li>远程服务提供者需要以某种形式提供服务调用相关的信息，包括但不限于服务接口定义、数据结构，或者中间态的服务定义文件，例如 Thrift 的 IDL 文件；服务调用者需要通过一定的途径获取远程服务调用相关信息，例如服务端接口定义 Jar 包导入，获取服务端 IDL 文件等。</li><li>远程代理对象：服务调用者调用的服务实际是远程服务的本地代理，对于 Java 语言，它的实现就是 JDK 的动态代理，通过动态代理的拦截机制，将本地调用封装成远程服务调用。</li><li>通信：RPC 框架与具体的协议无关。</li><li>序列化：远程通信，需要将对象转换成二进制码流进行网络传输，不同的序列化框架，支持的数据类型、数据包大小、异常类型及性能等都不同。有的甚至支持用户自定义序列化框架（Hadoop Avro）。</li></ol><h2 id="2-2-实现一个简单的-RPC-框架"><a href="#2-2-实现一个简单的-RPC-框架" class="headerlink" title="2.2 实现一个简单的 RPC 框架"></a>2.2 实现一个简单的 RPC 框架</h2><ol><li>分四个聚合项目：Provider、Consumer、RpcFramework、ServiceApi。为了简单期间，RPC 核心和 ServiceApi 合并一个项目 C。</li><li>Provider 依赖 C 项目，Consumer 依赖 C 项目。这样 Provider 和 Consumer 都有了同一个顶级接口以及同版本的 RPC 框架。</li><li>RPC 框架提供 export() 用于 Provider 发布自己的实现类、refer() 用于 Consumer 调用对应的顶级接口。</li><li>refer() 方法用于生成代理，此代理每次执行方法都会调用 invoke() 方法，而 invoke() 方法实际通过 socket 连接 Provider ，将调用的方法名、参数等传递给 Provider。</li><li>export() 方法用于获取 Consumer 传递的方法名，参数等，以及自己暴露的接口实现类，来反射执行获取结果，并返回给 Consumer。</li><li>代理对象获取到了结果，返回给调用者。</li><li>Provider 使用了反射，用于将调用者的方法名、参数、自己暴露的服务调用执行获取结果。Consumer 使用了代理，每次执行方法，都会调用 invoke() 即将调用的方法名、参数、调用的接口传递给 Provider。实现远程服务的本地代理。</li><li><a href="6">参考的 GITHUB 地址</a></li></ol><h2 id="2-3-业界主流-RPC-框架"><a href="#2-3-业界主流-RPC-框架" class="headerlink" title="2.3 业界主流 RPC 框架"></a>2.3 业界主流 RPC 框架</h2><ol><li>Facebook 的 Apache Thrift。</li><li>Hadoop 的 Avro-RPC。</li><li>caucho 的 Hession。</li><li>Google 的 gRPC。</li></ol><h2 id="2-4-RPC-框架面临的挑战"><a href="#2-4-RPC-框架面临的挑战" class="headerlink" title="2.4 RPC 框架面临的挑战"></a>2.4 RPC 框架面临的挑战</h2><ol><li>提供服务的机器越来越多，服务 URL 配置管理变得非常困难（服务发布订阅中心）。</li><li>服务间依赖关系变得错综复杂，甚至分不清哪个应用要在哪个应用之前启动（链路追踪）。</li><li>某个服务调用量特别大，需要加机器。为了解决容量规划问题，需要采集服务调用 KPI 数据，进行汇总和分析，计算出服务部署实例数和服务器的配置规格。</li><li>服务上线容易下线难，下线通知，需要统一的服务生命周期管理流程进行管控，如何保证敏感服务不被误调用，服务的访问安全策略又如何制定？</li><li>服务治理问题。</li></ol><h1 id="3-SOA-服务化架构"><a href="#3-SOA-服务化架构" class="headerlink" title="3 SOA 服务化架构"></a>3 SOA 服务化架构</h1><p>SOA 是一种粗粒度、松耦合的以服务为中心的架构，接口之间通过定义明确的协议和接口进行通信。  </p><h2 id="3-1-面向服务设计的原则"><a href="#3-1-面向服务设计的原则" class="headerlink" title="3.1 面向服务设计的原则"></a>3.1 面向服务设计的原则</h2><ol><li>服务可服用：不管是否存在即时复用的机会，服务均被设计为支持潜在的可复用。</li><li>服务共享一个标准契约：IDL 文件、Java 接口定义、甚至是一个接口说明文档。</li><li>服务是松耦合的：服务被设计为功能相对独立、尽量不依赖其它服务的独立功能提供者。</li><li>服务是底层逻辑的抽象：只有经服务契约所暴露的服务队外部世界可见，契约之外底层的实现逻辑是不可见的。</li><li>服务是可组合、可编排的：多个服务可能被编排组合成一个新的服务。</li><li>服务是可自治的：逻辑由服务所控制，并位于一个清晰的边界内，服务已经在边界内被控制，不依赖于其它服务。</li><li>服务是无状态的：这意味着要讲状态管理移至他处。</li><li>服务是可被自动发现的：服务发布上线后，允许被其它消费者自动发现。服务下线后，允许消费者接收服务下线通知。</li></ol><h2 id="3-2-服务治理"><a href="#3-2-服务治理" class="headerlink" title="3.2 服务治理"></a>3.2 服务治理</h2><p>SOA 服务治理主要包括如下几个方面：</p><ol><li>服务定义：SOA 治理最基础的方面就是监视服务的创建过程。</li><li>服务生命周期管理：服务需要进行规划、设计、实现、部署、维护、下线主要阶段。</li><li>服务版本治理：新版本的兼容性。</li><li>服务注册中心：服务提供者如何发布服务？服务消费者如何订阅服务？</li><li>服务监控：服务监控中心需要对服务的调用时延、成功率、吞吐率等数据进行实时采样和汇总。</li><li>运行期服务质量保障：包括服务限流、服务迁入迁出、服务升降级、服务权重调整和服务超时控制等，通过运行期的动态治理，可以在不重启服务的前提下达到快速提升服务运行质量的目标。</li><li>快速的故障定界定位手段：大规模分布式环境下海量业务/平台日志的采集、汇总和实时在线检索；分布式消息跟踪。</li><li>服务安全：是否允许任何人调用任何服务，数据敏感型服务是否允许所有用户访问所有数据，交互数据是否需要进行保护，服务的安全认证等。服务安全访问策略有多重，例如动态生成 Token 的方式做安全访问授权。</li></ol><h1 id="4-微服务架构"><a href="#4-微服务架构" class="headerlink" title="4 微服务架构"></a>4 微服务架构</h1><p>微服务架构（MSA）是一种服务化架构风格。<br>SOA 架构解决了应用服务化问题，但是随着服务规模越来越大、服务治理越来越多，微服务架构风格应运而生。微服务架构的主要特征如下：  </p><ol><li>原子服务。</li><li>高密度部署：利用LXC（例如 Docker）实现容器级部署。</li><li>敏捷交付：服务由小研发团队负责设计、开发、测试、部署、线上治理、灰度发布和下线，运维整个生命周期支撑，实现真正的 DevOps。</li><li>微自治：服务足够小，功能单一，可以独立打包、部署、升级、回滚和弹性伸缩，不依赖其它服务，实现局部自治。</li></ol><p>相对于 SOA，主要差异如下：  </p><ol><li>服务拆分粒度。</li><li>服务依赖：SOA 尽量重用，微服务功能单一独立。</li><li>服务规模：SOA 服务粒度大，多数会采用多个服务合并打 war 包，因此服务实例数比较有限。微服务强调尽可能拆分，同时很多服务会独立部署。</li><li>架构差异。</li><li>服务治理。</li><li>敏捷交付。</li></ol><h1 id="5-个人理解总结"><a href="#5-个人理解总结" class="headerlink" title="5 个人理解总结"></a>5 个人理解总结</h1><p><img src="http://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/learn/distributed_principle_prictice/1_5.png" alt=""></p><ol><li>MVC架构：在于多个功能部署同一个进程，一个 war 包，通过 HTTP 请求来实现互相的调用。重点在于前后端分离。</li><li>RPC架构：将核心和公共业务抽取出来，独立运行进程，使用 RPC 调用服务屏蔽底层通信逻辑。重点在于业务复用以及通用拆分。</li><li>SOA架构：服务生命周期管控和SOA服务治理是关键。</li><li>微服务架构：敏捷开发、持续交付、DevOps理论，基于 Docker 等轻量级容器。重点在于独立打包、部署和升级，小团队敏捷交付，交付周期短。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-传统垂直应用架构&quot;&gt;&lt;a href=&quot;#1-传统垂直应用架构&quot; class=&quot;headerlink&quot; title=&quot;1 传统垂直应用架构&quot;&gt;&lt;/a&gt;1 传统垂直应用架构&lt;/h1&gt;&lt;p&gt;以经典的 MVC 垂直架构为例，通常分三层：  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="分布式服务框架原理与实践" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    
    
  </entry>
  
  <entry>
    <title>一、bash shell 命令</title>
    <link href="http://www.liwenguang.cn/2018/05/16/linux_cli_shell/1.html/"/>
    <id>http://www.liwenguang.cn/2018/05/16/linux_cli_shell/1.html/</id>
    <published>2018-05-16T15:51:00.000Z</published>
    <updated>2018-05-16T15:51:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-bash-手册"><a href="#1-bash-手册" class="headerlink" title="1. bash 手册"></a>1. bash 手册</h3><p>用于查看命令的具体详情</p><p>man xxx</p><h2 id="2-ls-文件和目录列表"><a href="#2-ls-文件和目录列表" class="headerlink" title="2. ls 文件和目录列表"></a>2. ls 文件和目录列表</h2><p>-a 显示隐藏文件<br>文件名支持 <code>*？</code> 符号过滤  </p><h3 id="3-处理文件"><a href="#3-处理文件" class="headerlink" title="3. 处理文件"></a>3. 处理文件</h3><p>-i 询问参数<br>touch<br>cp file1 file2：复制文件。参数 -R 用于递归复制文件<br>mv file1 file2：移动文件rm file1：删除文件，文件名支持<code>?*</code></p><h3 id="4-处理目录"><a href="#4-处理目录" class="headerlink" title="4. 处理目录"></a>4. 处理目录</h3><p>mkdir：创建目录。-p 创建多个目录和子目录<br>rmdir：删除空目录rm -rf：递归删除，-r 递归遍历，-f 删除不提示</p><h3 id="5-查看文件内容"><a href="#5-查看文件内容" class="headerlink" title="5. 查看文件内容"></a>5. 查看文件内容</h3><p>file file1：获取文件的类型<br>cat file1：显示文本所有内容，参数 -n 加上行数，参数 -b 只给有内容的行加行数<br>more file1：<br>less file1：<br>tail file1：参数 -f，动态查看文件内容</p><h3 id="6-检测程序"><a href="#6-检测程序" class="headerlink" title="6. 检测程序"></a>6. 检测程序</h3><p>ps： -ef<br>top：实时检测，q 退出<br>kill PID：-9 参数强制<br>killall Name：关闭进程名，可以使用通配符</p><h3 id="7-检测磁盘空间"><a href="#7-检测磁盘空间" class="headerlink" title="7. 检测磁盘空间"></a>7. 检测磁盘空间</h3><p>mount：挂载媒体的<br>unmount：移除可移动设备<br>sort file：文件排序<br>grep pattern file：在 file 文件中查找 pattern 的行。-v 参数反向搜索<br>gzip/gunzip：压缩解压文件tar：-A 追加归档，-x 提取文件</p><h3 id="8-理解-shell"><a href="#8-理解-shell" class="headerlink" title="8. 理解 shell"></a>8. 理解 shell</h3><p>&amp;：将任务置入后台模式<br>which 命令：查看命令的对应路径<br>history：最近的使用过的命令列表  </p><h3 id="9-使用Linux环境变量"><a href="#9-使用Linux环境变量" class="headerlink" title="9. 使用Linux环境变量"></a>9. 使用Linux环境变量</h3><p>查看环境全局变量：printenv/env<br>查看环境局部变量：set<br>export：将一个局部变量的key导出到全局环境中  </p><h3 id="10-管理文件系统"><a href="#10-管理文件系统" class="headerlink" title="10. 管理文件系统"></a>10. 管理文件系统</h3><ol><li>ext 文件系统：单文件不能超过2GB。</li><li>ext2 文件系统：保存更多信息。</li><li>日志文件系统：先将数据直接写入存储设备再更新索引节点表-&gt;文件的更改写入到临时文件中，数据成功写到存储设备和索引节点表后再删除对应的日志条目。</li><li>ext3 文件系统：在 ext2 基础上，给每个存储设备增加了一个日志文件。</li><li>ext4 文件系统。</li></ol><h3 id="11-安装软件程序"><a href="#11-安装软件程序" class="headerlink" title="11. 安装软件程序"></a>11. 安装软件程序</h3><ol><li>Debian（Ubuntu）：dpkg 命令。</li><li>Red Hat：rpm 命令。yum 命令。</li></ol><h3 id="12-使用编辑器"><a href="#12-使用编辑器" class="headerlink" title="12. 使用编辑器"></a>12. 使用编辑器</h3><p>vim<br>nano<br>emacs</p><h2 id="13-参考"><a href="#13-参考" class="headerlink" title="13. 参考"></a>13. 参考</h2><ol><li>初识Linux shell：<a href="http://www.ituring.com.cn/book/tupubarticle/11430" target="_blank" rel="external">http://www.ituring.com.cn/book/tupubarticle/11430</a></li><li>走进shell：<a href="http://www.ituring.com.cn/book/tupubarticle/11431" target="_blank" rel="external">http://www.ituring.com.cn/book/tupubarticle/11431</a></li><li>基本的bash shell命令：<a href="http://www.ituring.com.cn/book/tupubarticle/11432" target="_blank" rel="external">http://www.ituring.com.cn/book/tupubarticle/11432</a></li><li>更多的bash shell命令： <a href="http://www.th7.cn/system/lin/201704/210752.shtml" target="_blank" rel="external">http://www.th7.cn/system/lin/201704/210752.shtml</a></li><li>理解shell：<a href="http://www.th7.cn/system/lin/201704/211006.shtml" target="_blank" rel="external">http://www.th7.cn/system/lin/201704/211006.shtml</a></li><li>使用Linux环境变量：<a href="http://www.voidcn.com/article/p-vizgjbtx-bmq.html" target="_blank" rel="external">http://www.voidcn.com/article/p-vizgjbtx-bmq.html</a></li><li>理解Linux文件权限：<a href="http://www.voidcn.com/article/p-whblgnni-bmq.html" target="_blank" rel="external">http://www.voidcn.com/article/p-whblgnni-bmq.html</a></li><li>管理文件系统：<a href="https://www.aliyun.com/jiaocheng/123749.html" target="_blank" rel="external">https://www.aliyun.com/jiaocheng/123749.html</a></li><li>安装软件程序：<a href="https://www.aliyun.com/jiaocheng/123748.html" target="_blank" rel="external">https://www.aliyun.com/jiaocheng/123748.html</a></li><li>使用编辑器：<a href="http://www.voidcn.com/article/p-fokuslvn-bnt.html" target="_blank" rel="external">http://www.voidcn.com/article/p-fokuslvn-bnt.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-bash-手册&quot;&gt;&lt;a href=&quot;#1-bash-手册&quot; class=&quot;headerlink&quot; title=&quot;1. bash 手册&quot;&gt;&lt;/a&gt;1. bash 手册&lt;/h3&gt;&lt;p&gt;用于查看命令的具体详情&lt;/p&gt;
&lt;p&gt;man xxx&lt;/p&gt;
&lt;h2 id=&quot;2
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Linux命令行与shell脚本编程大全" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Eshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%A4%A7%E5%85%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>二、shell 脚本</title>
    <link href="http://www.liwenguang.cn/2018/05/16/linux_cli_shell/2.html/"/>
    <id>http://www.liwenguang.cn/2018/05/16/linux_cli_shell/2.html/</id>
    <published>2018-05-16T15:51:00.000Z</published>
    <updated>2018-05-16T15:51:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="13-参考"><a href="#13-参考" class="headerlink" title="13 参考"></a>13 参考</h2><p>第十一章 构建基本脚本：<a href="http://www.suoniao.com/article/15930" target="_blank" rel="external">http://www.suoniao.com/article/15930</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;13-参考&quot;&gt;&lt;a href=&quot;#13-参考&quot; class=&quot;headerlink&quot; title=&quot;13 参考&quot;&gt;&lt;/a&gt;13 参考&lt;/h2&gt;&lt;p&gt;第十一章 构建基本脚本：&lt;a href=&quot;http://www.suoniao.com/article/15930&quot;
      
    
    </summary>
    
      <category term="读书笔记" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Linux命令行与shell脚本编程大全" scheme="http://www.liwenguang.cn/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8Eshell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%E5%A4%A7%E5%85%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>面试自我反省总结</title>
    <link href="http://www.liwenguang.cn/2018/05/08/tech/learn_what_how_why.html/"/>
    <id>http://www.liwenguang.cn/2018/05/08/tech/learn_what_how_why.html/</id>
    <published>2018-05-08T13:51:00.000Z</published>
    <updated>2018-05-16T15:51:00.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-第一个面试大概是年前还差半个月放假的某天晚上，一个电话面试，杭州的一个偏传统公司，应该是主要做-ERP-这类的系统，最后-HR-等年后通知就没通知了。"><a href="#1-第一个面试大概是年前还差半个月放假的某天晚上，一个电话面试，杭州的一个偏传统公司，应该是主要做-ERP-这类的系统，最后-HR-等年后通知就没通知了。" class="headerlink" title="1. 第一个面试大概是年前还差半个月放假的某天晚上，一个电话面试，杭州的一个偏传统公司，应该是主要做 ERP 这类的系统，最后 HR 等年后通知就没通知了。"></a>1. 第一个面试大概是年前还差半个月放假的某天晚上，一个电话面试，杭州的一个偏传统公司，应该是主要做 ERP 这类的系统，最后 HR 等年后通知就没通知了。</h3><p>主要问了 java 集合，包括里面 List、Set、Map 各个区别以及相关算法、Spring 的设计模式、Spring MVC 和 Servlet 的联系区别、Spring 的相关源码，我当时只说了 Spring MVC 启动、运行源码流程，@Autowire 注入的时候的 AutowireAnnotationBeanPostProcessor 的相关逻辑，顺带讲了 Bean 的生命周期，循环注入等，还有一些常见的面试题给忘了。</p><h3 id="2-第二个面试是4-26号武汉小米的面试，以为一面不会过，没想到过了，可惜二面BOS没过，主要是对自己的项目没答好，可能由于没怎么复习以前的项目，不过学了很多。"><a href="#2-第二个面试是4-26号武汉小米的面试，以为一面不会过，没想到过了，可惜二面BOS没过，主要是对自己的项目没答好，可能由于没怎么复习以前的项目，不过学了很多。" class="headerlink" title="2. 第二个面试是4.26号武汉小米的面试，以为一面不会过，没想到过了，可惜二面BOS没过，主要是对自己的项目没答好，可能由于没怎么复习以前的项目，不过学了很多。"></a>2. 第二个面试是4.26号武汉小米的面试，以为一面不会过，没想到过了，可惜二面BOS没过，主要是对自己的项目没答好，可能由于没怎么复习以前的项目，不过学了很多。</h3><p>一面先问 hashmap 的 put，currenthashmap 的 put，以及 size，然后是 ThreadLocal，订阅模式、命令模式、代理模式，sql，组合索引，手写一些 sql 问是否用到了索引，手写一个 幻读，隔离级别与事务传播，那个幻读没写出来，然后被一面的面试官评价为基础可以但是 sql 不行，唉，然后问我最得意的项目，我说的是一个基于 ZooKeeper 的一个项目，然后问了 zk 的一些知识，两阶段提交、paxos（这个没答出来）、CAP、BASE，然后问如何实现一个分布式锁，然后问了项目的一些问题，涉及到了线程池。<br>二面直接让我把一个 BI 的项目技术架构图画出来，然后问 ETL ，RPC 和 http 的区别，然后其它一些小问题，跟我说要多敲代码，不是本专业只能要非常突出的代码能力才行。。。然后谈论了业务和技术，最后直接跟我说没过。比较奇怪没有问 JVM，可能是三面才会问这么高深的吧。。。<br>事后也把我做的项目都复习总结拿出来重新过了一遍，学了很多，然后好好复习，准备下一个面试。</p><h3 id="3-第三个面试是上海的一家创业公司，笔试，两轮技术，HR，拿到-offer-没去。"><a href="#3-第三个面试是上海的一家创业公司，笔试，两轮技术，HR，拿到-offer-没去。" class="headerlink" title="3. 第三个面试是上海的一家创业公司，笔试，两轮技术，HR，拿到 offer 没去。"></a>3. 第三个面试是上海的一家创业公司，笔试，两轮技术，HR，拿到 offer 没去。</h3><p>笔试：两个类A extend B，考察静态方法和构造方法的执行顺序，二分查找法，mysql 的 having order 等。<br>技术面试，一问 hashmap 然后问简历项目。最后问多个线程同时下载报表如何下载。主问简历。<br>二轮BOS，一问 某个业务从请求到最后日志记录的业务全过程。然后聊了很多，treemap 和 hashmap，git rebase merge，最后一个问题是一千个排好序的文件，如果成为一个大的排序好的文件。大概这么多</p><h3 id="4-第四个面试是上海同事推荐，两面技术，拿到-offer。"><a href="#4-第四个面试是上海同事推荐，两面技术，拿到-offer。" class="headerlink" title="4. 第四个面试是上海同事推荐，两面技术，拿到 offer。"></a>4. 第四个面试是上海同事推荐，两面技术，拿到 offer。</h3><p>一面电话：集合、threadlocal、锁、线程池。多态、继承、封装的理解，主要是基础，具体问的大概忘了，并不深入。<br>二面聊天：一问，nginx 实现负载均衡的方式，底层如何实现负载均衡，zk 的实际案例，为什么用 zk，内部如何选举。大概这么多。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-第一个面试大概是年前还差半个月放假的某天晚上，一个电话面试，杭州的一个偏传统公司，应该是主要做-ERP-这类的系统，最后-HR-等年后通知就没通知了。&quot;&gt;&lt;a href=&quot;#1-第一个面试大概是年前还差半个月放假的某天晚上，一个电话面试，杭州的一个偏传统公司，
      
    
    </summary>
    
      <category term="小结" scheme="http://www.liwenguang.cn/categories/%E5%B0%8F%E7%BB%93/"/>
    
    
  </entry>
  
  <entry>
    <title>JVM_Memory</title>
    <link href="http://www.liwenguang.cn/2018/04/13/A2B_Java/4_JVM_Memory.html/"/>
    <id>http://www.liwenguang.cn/2018/04/13/A2B_Java/4_JVM_Memory.html/</id>
    <published>2018-04-13T10:00:00.000Z</published>
    <updated>2018-04-13T11:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>转自：<a href="https://www.cnblogs.com/dolphin0520/p/3613043.html" target="_blank" rel="external">https://www.cnblogs.com/dolphin0520/p/3613043.html</a></p><h1 id="1-运行时数据区（Runtime-Data-Area）"><a href="#1-运行时数据区（Runtime-Data-Area）" class="headerlink" title="1. 运行时数据区（Runtime Data Area）"></a>1. 运行时数据区（Runtime Data Area）</h1><ol><li>Java 栈（VM Stack）</li><li>本地方法栈（Native Method Stack）</li><li>程序计数器（Program Counter Register）</li><li>堆（Heap）</li><li>方法区（Method Area）</li></ol><p><img src="https://images0.cnblogs.com/i/288799/201405/281726404166686.jpg" alt="1"></p><h1 id="2-各个区具体存储了什么数据"><a href="#2-各个区具体存储了什么数据" class="headerlink" title="2. 各个区具体存储了什么数据"></a>2. 各个区具体存储了什么数据</h1><h2 id="2-1-程序计数器"><a href="#2-1-程序计数器" class="headerlink" title="2.1 程序计数器"></a>2.1 程序计数器</h2><p>由于在JVM中，多线程是通过线程轮流切换来获得CPU执行时间的，因此，在任一具体时刻，一个CPU的内核只会执行一条线程中的指令，因此，为了能够使得每个线程都在线程切换后能够恢复在切换之前的程序执行位置，每个线程都需要有自己独立的程序计数器，并且不能互相被干扰，否则就会影响到程序的正常执行次序。因此，可以这么说，程序计数器是每个线程所私有的。  </p><p>在JVM规范中规定，如果线程执行的是非native方法，则程序计数器中保存的是当前需要执行的指令的地址；如果线程执行的是native方法，则程序计数器中的值是undefined。  </p><p>由于程序计数器中存储的数据所占空间的大小不会随程序的执行而发生改变，因此，对于程序计数器是不会发生内存溢出现象(OutOfMemory)的。</p><h2 id="2-2-Java-栈"><a href="#2-2-Java-栈" class="headerlink" title="2.2 Java 栈"></a>2.2 Java 栈</h2><p>Java栈中存放的是一个个的栈帧，每个栈帧对应一个被调用的方法，在栈帧中包括局部变量表(Local Variables)、操作数栈(Operand Stack)、指向当前方法所属的类的运行时常量池（运行时常量池的概念在方法区部分会谈到）的引用(Reference to runtime constant pool)、方法返回地址(Return Address)和一些额外的附加信息。当线程执行一个方法时，就会随之创建一个对应的栈帧，并将建立的栈帧压栈。当方法执行完毕之后，便会将栈帧出栈。因此可知，线程当前执行的方法所对应的栈帧必定位于Java栈的顶部。  </p><p><img src="https://images0.cnblogs.com/i/288799/201405/291429030562182.jpg" alt="2">  </p><p>局部变量表：对于基本数据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。局部变量表的大小在编译器就可以确定其大小了，因此在程序执行期间局部变量表的大小是不会改变的。  </p><p>操作数栈：想必学过数据结构中的栈的朋友想必对表达式求值问题不会陌生，栈最典型的一个应用就是用来对表达式求值。想想一个线程执行方法的过程中，实际上就是不断执行语句的过程，而归根到底就是进行计算的过程。因此可以这么说，程序中的所有计算过程都是在借助于操作数栈来完成的。  </p><p>指向运行时常量池的引用：因为在方法执行的过程中有可能需要用到类中的常量，所以必须要有一个引用指向运行时常量。  </p><p>方法返回地址：当一个方法执行完毕之后，要返回之前调用它的地方，因此在栈帧中必须保存一个方法返回地址。  </p><p>由于每个线程正在执行的方法可能不同，因此每个线程都会有一个自己的Java栈，互不干扰。</p><h2 id="2-3-本地方法栈"><a href="#2-3-本地方法栈" class="headerlink" title="2.3 本地方法栈"></a>2.3 本地方法栈</h2><p>本地方法栈与Java栈的作用和原理非常相似。区别只不过是Java栈是为执行Java方法服务的，而本地方法栈则是为执行本地方法（Native Method）服务的。<br>在JVM规范中，并没有对本地方发展的具体实现方法以及数据结构作强制规定，虚拟机可以自由实现它。在HotSopt虚拟机中直接就把本地方法栈和Java栈合二为一。</p><h2 id="2-4-堆"><a href="#2-4-堆" class="headerlink" title="2.4 堆"></a>2.4 堆</h2><p>Java中的堆是用来存储对象本身的以及数组（当然，数组引用是存放在Java栈中的）。<br>Java的垃圾回收机制会自动进行处理。因此这部分空间也是Java垃圾收集器管理的主要区域。另外，堆是被所有线程共享的，在JVM中只有一个堆。</p><h2 id="2-5-方法区"><a href="#2-5-方法区" class="headerlink" title="2.5 方法区"></a>2.5 方法区</h2><p>方法区在JVM中也是一个非常重要的区域，它与堆一样，是被线程共享的区域。在方法区中，存储了每个类的信息（包括类的名称、方法信息、字段信息）、静态变量、常量以及编译器编译后的代码等。  </p><p>在Class文件中除了类的字段、方法、接口等描述信息外，还有一项信息是常量池，用来存储编译期间生成的字面量和符号引用。  </p><p>在方法区中有一个非常重要的部分就是运行时常量池，它是每一个类或接口的常量池的运行时表示形式，在类和接口被加载到JVM后，对应的运行时常量池就被创建出来。当然并非Class文件常量池中的内容才能进入运行时常量池，在运行期间也可将新的常量放入运行时常量池中，比如String的intern方法。  </p><p>在JVM规范中，没有强制要求方法区必须实现垃圾回收。很多人习惯将方法区称为“永久代”，是因为HotSpot虚拟机以永久代来实现方法区，从而JVM的垃圾收集器可以像管理堆区一样管理这部分区域，从而不需要专门为这部分设计垃圾回收机制。不过自从JDK7之后，Hotspot虚拟机便将运行时常量池从永久代移除了。</p><p></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转自：&lt;a href=&quot;https://www.cnblogs.com/dolphin0520/p/3613043.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.cnblogs.com/dolphin0520/p/3613
      
    
    </summary>
    
      <category term="Java 拾遗" scheme="http://www.liwenguang.cn/categories/Java-%E6%8B%BE%E9%81%97/"/>
    
    
  </entry>
  
</feed>
