---
title: 压测性能总结
date: 2019-10-27 23:20:00
updated: 2019-10-27 23:20:00
tags:
  - 性能优化
categories: 
  - 实践
  - 技术小结
comments: true
permalink: tech/11_performance_sum.html    
---

# 0. 背景

临近双11，公司对所有的接口都使用阿里云的全链路压测工具做压测，比如首页的 TPS 是3000，支付的 TPS 是 60，根据不同的接口做不同的策略。其中数值是根据平时的5倍计算得出的。  
这篇博文就是使用阿里云的 arms 监控（APM的一种，类似 skywalking，可以查看请求的每个链路）以及 PTS（做压测的一种工具）对两次压测的优化总结

# 1. MySQL

在支付项目中使用 MySQL 用于存储支付参数、支付结果等信息，主要是短查询和长写入，整个支付下单事务较长，而且由于正在拆解服务，还没有将数据库独立出来，因为数据库性能会收到其它项目的影响从而影响本项目，这是没法避免的

查看最大连接数：
![][1]

根据最大连接数，以及多少个集群，来设置项目的连接数，那什么时候才知道是连接数的问题呢？当你在接口的时候，发现某个访问数据库的操作需要5s，但是又发现你查看数据库的语句最慢的才1s，那你就需要怀疑是否是在等待连接而耗费很大量的时间

是否项目上有多余的事务注解，因为我就犯了这个错。原来的某个服务 A 本来是个有更新操作的，但是优化后，将更新操作让 MQ 做，而服务 A 里面只有一个查询和发 MQ，但是我忘记去掉该服务的 Transaction 注解，导致在压测的时候，该服务的响应时间是1分钟，查看链路发现是一个 select 语句就1分钟~当去掉 Transaction 后变成了10ms。

# 2. ONS

ons 是 rocketmq 的商业版，使用基本和 rocketmq 一致。但是没有 rocketmq 好用，我之前公司使用自己搭建的 rocketmq，有问题基本debug，可以能大概定位问题。但是 ons 由于是闭源，只能提工单到他们的工作人员，等待反馈。但是 ons 适合刚初创企业，当业务发展量到了一定程度，使用 rocketmq 是必然的结果！

观察消息的生产消费量，支付相关的消息平时相对来说不是很多，然后再看压测时候的消息大致是多少，当时在压测过程中由于消息使用普通消息，导致没有达到削峰的功能，CPU飙到了 70%，最后在分析该业务后，发现该业务可以接受大概30s的延迟，因此果断使用随机延迟消息，做削峰填谷，将 CPU 稳定在了 10%，提升很大。
>但是这里有个疑问，我之前了解 rocketmq 知道它使用延迟消息是使用延迟级别的队列实现，即：你有几个延迟级别，就需要多少个额外的队列，但是在 ons，我使用的随机延迟消息，理论上ons那就支持了无限的延迟队列，但是这是不可能的，因此它肯定有自己更好的延迟队列实现！

消息队列参考文档的最佳实践是，一个微服务用一个 GroupId，项目内部一级业务类型，使用 Topic 区分。二级业务使用 TAG 区分。例如我这边的支付相关消息使用 Pay_Topic，下面一些比如退款或转账的具体业务使用 TAG 区分，具体的最佳实践参考文档：https://help.aliyun.com/document_detail/95837.html?spm=a2c4g.11174283.6.624.3a945793jfF9XT

其中一个插曲，是关于消息负载的问题，由于阿里他们消息负载有问题（他们也承认了，正在优化），因此有经常某台机器负载堆积消息尤其严重，而有的机器又很空闲。他们答应尽快解决，我这边暂时使用 sentinel 做消息的限流，这也侧面验证其实自建消息队列是很有必要的，至少在消息的负载上，我们可以透明化，一是消息到队列的负载，二是队列到消费者的负载，都可以控制。

# 3. Redis

关于 Redis 我这边并没有使用很多，因为支付一是需要走主库，二是需要实时尽量少走缓存，除非是支付相关的边缘业务，查询很多，才会考虑使用 Redis 缓存，毕竟有技术成本。  
  
唯一使用 Redis 的地方是保证消息消费的幂等性。由于项目使用的 ons-client 是老的版本，有一些BUG，但是新的版本和老的版本部门协议又有不同，而老的版本更新到新版本成本太大，需要同时改其它所有依赖的项目 ons-client 版本，因为要解决这个 BUG，而这个 BUG 就是 exactly-once 的使用。它的原理如下：客户端建一张消息消费表，并在代码注入使用它的 MQDataSouce，该 datasource 会在消息前后做切面，加入状态的变更和判定，例如：消费状态未消费、消费中、消费完成、消费异常等，而状态的变更写入数据库是和业务的数据库属于同一个事务，从而保证了消息的幂等————通过额外一个消费进度表来实现。但是由于有 BUG，这个状态判定有个小问题，因此在最外层加入了 Redis 实现了类似的功能，对同一个 MessageKey 记录消费状态，来实现消息的去重。为什么不适用数据库表来实现呢？一是因为效率，二是方便。唯一的问题是 Redis 挂掉的问题？但是说实话，Redis 挂掉的几率基本和 MySQL 挂掉几率基本一样，因为我们都是使用的阿里云集群机器。

# 4. 内部项目接口

内部使用 dubbo 调用，优化基本是在 dubbo 配置上，第一个是将 threadpool 将 cached 改为 fixed，数量默认为 200，这是参考了arms监控中的线程池变化设定的，而且机器性能也好，不过还需要下次压测查看结果，毕竟线程上下文切换也不知道损耗多少。第二个是超时时间，我这边设置为 3000 ms，因为支付不会要求那么实时，另外使用了 redisson 做重复请求的锁，锁 3000 ms，避免多次点击，由于业务正在优化，某些业务还不支持幂等，重复请求会有点问题，基本在 3 秒内支付相关流程事务执行完，状态写入成功，就没什么大问题了。第三个是 loadbalance 策略，修改为 leastactive，另外，因为我们用的 nacos 有个权重，不过这个我还没用，可以以后如果机器性能不均匀有个参考优化点。

# 5. 第三方接口

第三方接口慢，没法避免，而且有的付费接口是基于 TPS 购买的，因为必须要使用限流，不然返回都是错误，用 sentinel 的 callback 就很方便。其它类似的限流工具也差不多，根据漏桶算法，做 TPS 判定，也可以选择使用 RT 做限流。

# 6. JVM 优化

jvm 优化主要是参考的 https://opts.console.perfma.com/ ，原来的参数是：
```
-server -Xms4096m -Xmx4096m -XX:NewSize=1024m  -XX:MaxNewSize=1024m -XX:PermSize=512M -XX:MaxPermSize=512m
```
机器 4核8G，现在的参数调整为：
```
-server -Xms5440M -Xmx5440M -Xmn1984M -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m
```

其中主要参考了压测时的堆栈内存变化，其中可以看出 10-22 的变化：

![][2]

# 7. 后台任务分离

这个主要是将后台的定时任务全部迁入到一个专门的执行器项目，使用 xxl-job 来控制后台任务的执行，避免定时任务执行时的性能抖动，影响核心接口

# 8. 总结

1. MySQL

慢SQL：但是我这边基本没有
连接数：这个根据阿里云 RDS 的性能和项目数做调整
是否有不必要的事务：检查去掉不必要的事务
死锁：其实死锁还是有，很难根本解决，只能说减少概率，这个之前也写死锁总结博文，但是因为这个暂时不是性能瓶颈，因为在之后会花时间再解决。

2. 消息队列

消息是否可以接受延迟？，如果可以，那么就随机延迟或者几个延迟级别随机选择。  
机器消费消息是否负载均衡？如果不均衡，那么看是发消息到队列不均衡，还是队列到消费者不均衡。

3. Redis

能不用缓存就不用缓存，如果性能问题，必须上缓存，那么要考虑缓存一致的问题，其实我在公司经常听到测试说，为什么这边修改但是用户那边还没改动，根本原因是，缓存在设计的时候不合理，乱用，而不考虑手动缓存失效，只能等待一定时间取失效，这是不合理的。  
Redis 不可用我暂时还没碰到，可能是使用量不大，不过性能抖动倒是碰到过，上家用的腾讯云，半夜会超时什么的，这个没办法，推荐阿里云~。

4. 内部接口

我们都是用 dubbo 做项目之间的请求

别人依赖你：别人依赖你的接口服务，那么尽量保证能异步就异步，日志通过 filter 拦截进出口的日志，方便调试。还有一个是关于 apm 的使用，我们使用了 skywalking，因为我加入了全局链路 token，方便跟踪某个请求，这个对定位问题很方便。自己提供的接口服务能加上限流控制就加上，关键时候设置限流有奇效。
你依赖别人：考虑当别人项目不可用时，你会发生什么，就行了。最简单的就是请求超时时间以及负载策略。

5. JVM 优化

推荐参考 https://opts.console.perfma.com/，输入自己的机器参数，自动给你生成相关参数，最后在观察项目的 JVM 实际情况，来做调整

6. 服务分离

前后台服务分离：后台定时任务分离独立为一个项目，提供给别人的接口服务独立为一个项目
核心业务分离：这个我没有实战，但是如果以后业务量膨胀，我会使用该方法，核心业务不能挂~


[1]: https://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/somephoto/2019-10-28MySQL%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0.png
[2]: https://leran2deeplearnjavawebtech.oss-cn-beijing.aliyuncs.com/somephoto/2019-10-28JVM%E5%9B%BE.png